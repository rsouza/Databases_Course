{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Databases\n",
    "\n",
    "### Miscellaneous Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"../SampleDBs/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving a txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(datapath, 'newfile.txt'), mode='w', encoding='utf-8') as f:\n",
    "    f.write('Weight\\t\\t72\\n')\n",
    "    f.write('Height\\t\\t183\\n')\n",
    "    f.write('Age\\t\\t44\\n')\n",
    "    f.write('Gender\\t\\tMasculine\\n')\n",
    "    f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving a txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(datapath, 'newfile.txt'), mode='r', encoding='utf-8') as f:\n",
    "    fulltext = f.read()\n",
    "    f.seek(0)\n",
    "    line = f.readline()\n",
    "    f.seek(0)\n",
    "    list_of_lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight\t\t72\n",
      "Height\t\t183\n",
      "Age\t\t44\n",
      "Gender\t\tMasculine\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(fulltext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight\t\t72\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Weight\\t\\t72\\n', 'Height\\t\\t183\\n', 'Age\\t\\t44\\n', 'Gender\\t\\tMasculine\\n', '\\n']\n"
     ]
    }
   ],
   "source": [
    "print(list_of_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#erasing file\n",
    "os.remove(os.path.join(datapath, 'newfile.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Numpy Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.    0.005 0.01  0.015 0.02  0.025 0.03  0.035 0.04  0.045 0.05  0.055\n",
      " 0.06  0.065 0.07  0.075 0.08  0.085 0.09  0.095 0.1   0.105 0.11  0.115\n",
      " 0.12  0.125 0.13  0.135 0.14  0.145 0.15  0.155 0.16  0.165 0.17  0.175\n",
      " 0.18  0.185 0.19  0.195 0.2   0.205 0.21  0.215 0.22  0.225 0.23  0.235\n",
      " 0.24  0.245 0.25  0.255 0.26  0.265 0.27  0.275 0.28  0.285 0.29  0.295\n",
      " 0.3   0.305 0.31  0.315 0.32  0.325 0.33  0.335 0.34  0.345 0.35  0.355\n",
      " 0.36  0.365 0.37  0.375 0.38  0.385 0.39  0.395 0.4   0.405 0.41  0.415\n",
      " 0.42  0.425 0.43  0.435 0.44  0.445 0.45  0.455 0.46  0.465 0.47  0.475\n",
      " 0.48  0.485 0.49  0.495 0.5   0.505 0.51  0.515 0.52  0.525 0.53  0.535\n",
      " 0.54  0.545 0.55  0.555 0.56  0.565 0.57  0.575 0.58  0.585 0.59  0.595\n",
      " 0.6   0.605 0.61  0.615 0.62  0.625 0.63  0.635 0.64  0.645 0.65  0.655\n",
      " 0.66  0.665 0.67  0.675 0.68  0.685 0.69  0.695 0.7   0.705 0.71  0.715\n",
      " 0.72  0.725 0.73  0.735 0.74  0.745 0.75  0.755 0.76  0.765 0.77  0.775\n",
      " 0.78  0.785 0.79  0.795 0.8   0.805 0.81  0.815 0.82  0.825 0.83  0.835\n",
      " 0.84  0.845 0.85  0.855 0.86  0.865 0.87  0.875 0.88  0.885 0.89  0.895\n",
      " 0.9   0.905 0.91  0.915 0.92  0.925 0.93  0.935 0.94  0.945 0.95  0.955\n",
      " 0.96  0.965 0.97  0.975 0.98  0.985 0.99  0.995 1.   ]\n"
     ]
    }
   ],
   "source": [
    "data = np.linspace(0,1,201)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(os.path.join(datapath, 'data.dat'), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.    0.005 0.01  0.015 0.02  0.025 0.03  0.035 0.04  0.045 0.05  0.055\n",
      " 0.06  0.065 0.07  0.075 0.08  0.085 0.09  0.095 0.1   0.105 0.11  0.115\n",
      " 0.12  0.125 0.13  0.135 0.14  0.145 0.15  0.155 0.16  0.165 0.17  0.175\n",
      " 0.18  0.185 0.19  0.195 0.2   0.205 0.21  0.215 0.22  0.225 0.23  0.235\n",
      " 0.24  0.245 0.25  0.255 0.26  0.265 0.27  0.275 0.28  0.285 0.29  0.295\n",
      " 0.3   0.305 0.31  0.315 0.32  0.325 0.33  0.335 0.34  0.345 0.35  0.355\n",
      " 0.36  0.365 0.37  0.375 0.38  0.385 0.39  0.395 0.4   0.405 0.41  0.415\n",
      " 0.42  0.425 0.43  0.435 0.44  0.445 0.45  0.455 0.46  0.465 0.47  0.475\n",
      " 0.48  0.485 0.49  0.495 0.5   0.505 0.51  0.515 0.52  0.525 0.53  0.535\n",
      " 0.54  0.545 0.55  0.555 0.56  0.565 0.57  0.575 0.58  0.585 0.59  0.595\n",
      " 0.6   0.605 0.61  0.615 0.62  0.625 0.63  0.635 0.64  0.645 0.65  0.655\n",
      " 0.66  0.665 0.67  0.675 0.68  0.685 0.69  0.695 0.7   0.705 0.71  0.715\n",
      " 0.72  0.725 0.73  0.735 0.74  0.745 0.75  0.755 0.76  0.765 0.77  0.775\n",
      " 0.78  0.785 0.79  0.795 0.8   0.805 0.81  0.815 0.82  0.825 0.83  0.835\n",
      " 0.84  0.845 0.85  0.855 0.86  0.865 0.87  0.875 0.88  0.885 0.89  0.895\n",
      " 0.9   0.905 0.91  0.915 0.92  0.925 0.93  0.935 0.94  0.945 0.95  0.955\n",
      " 0.96  0.965 0.97  0.975 0.98  0.985 0.99  0.995 1.   ]\n"
     ]
    }
   ],
   "source": [
    "new_data = np.loadtxt(os.path.join(datapath, 'data.dat'))\n",
    "print(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#erasing file\n",
    "os.remove(os.path.join(datapath, 'data.dat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.72865167]]\n",
      "[[0.05263158 0.41424254]]\n",
      "[[0.10526316 0.49498442]]\n",
      "[[0.15789474 0.48065259]]\n",
      "[[0.21052632 0.62067216]]\n",
      "[[0.26315789 0.17738839]]\n",
      "[[0.31578947 0.88995241]]\n",
      "[[0.36842105 0.53264059]]\n",
      "[[0.42105263 0.07352186]]\n",
      "[[0.47368421 0.3772164 ]]\n",
      "[[0.52631579 0.12462665]]\n",
      "[[0.57894737 0.86828776]]\n",
      "[[0.63157895 0.15304811]]\n",
      "[[0.68421053 0.73725966]]\n",
      "[[0.73684211 0.13985777]]\n",
      "[[0.78947368 0.00639617]]\n",
      "[[0.84210526 0.73638896]]\n",
      "[[0.89473684 0.00628633]]\n",
      "[[0.94736842 0.93772871]]\n",
      "[[1.         0.09788498]]\n"
     ]
    }
   ],
   "source": [
    "x = np.linspace(0, 1, 20)\n",
    "y = np.random.random(20)\n",
    "header = \"X-Column, Y-Column\\n\"\n",
    "header += \"This is a second line\"\n",
    "\n",
    "with open(os.path.join(datapath,'data2.dat'), 'wb') as f:\n",
    "#with open(os.path.join(datapath,'data2.dat'), 'w') as f:   #using text formatting and no binary files\n",
    "    np.savetxt(f, [], header=header)\n",
    "    for i in range(20):\n",
    "        data = np.column_stack((x[i], y[i]))\n",
    "        np.savetxt(f, data), print(data)\n",
    "        #f.write('{:4.1f} {:.4f}\\n'.format(x[i], y[i]))    #using text formatting and no binary files\n",
    "        f.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# X-Column, Y-Column\n",
      "# This is a second line\n",
      "0.000000000000000000e+00 7.286516700066931751e-01\n",
      "5.263157894736841813e-02 4.142425368454596413e-01\n",
      "1.052631578947368363e-01 4.949844234341568283e-01\n",
      "1.578947368421052544e-01 4.806525853568911488e-01\n",
      "2.105263157894736725e-01 6.206721584287625548e-01\n",
      "2.631578947368420907e-01 1.773883900160257987e-01\n",
      "3.157894736842105088e-01 8.899524059386328956e-01\n",
      "3.684210526315789269e-01 5.326405881450090307e-01\n",
      "4.210526315789473450e-01 7.352186366627488923e-02\n",
      "4.736842105263157632e-01 3.772163983115532915e-01\n",
      "5.263157894736841813e-01 1.246266486754834535e-01\n",
      "5.789473684210526550e-01 8.682877608836656602e-01\n",
      "6.315789473684210176e-01 1.530481090532087585e-01\n",
      "6.842105263157893802e-01 7.372596557228354719e-01\n",
      "7.368421052631578538e-01 1.398577713315550808e-01\n",
      "7.894736842105263275e-01 6.396173138688232562e-03\n",
      "8.421052631578946901e-01 7.363889607695421891e-01\n",
      "8.947368421052630527e-01 6.286331248876897426e-03\n",
      "9.473684210526315264e-01 9.377287104046299060e-01\n",
      "1.000000000000000000e+00 9.788497576911392439e-02\n"
     ]
    }
   ],
   "source": [
    "! cat ../SampleDBs/data2.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#erasing file\n",
    "os.remove(os.path.join(datapath, 'data2.dat'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "data = [1, 1.2, 'a', 'b']\n",
    "\n",
    "with open(os.path.join(datapath, 'data.pkl'), 'wb') as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1.2, 'a', 'b']\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(datapath, 'data.pkl'), 'rb') as f:\n",
    "    new_data = pickle.load(f)\n",
    "\n",
    "print(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#erasing file\n",
    "os.remove(os.path.join(datapath, 'data.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acessing CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile = \"fakedata.csv\"\n",
    "datafile = os.path.join(datapath, csvfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using pure Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Fatima',\n",
       "  'email': 'Quisque.varius@Integervitae.org',\n",
       "  'birthdate': '11-25-01'},\n",
       " {'name': 'Katelyn',\n",
       "  'email': 'mi.pede.nonummy@Sedid.ca',\n",
       "  'birthdate': '11-27-03'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "with open(datafile, \"r\") as f:\n",
    "    keys = f.readline().split('|')\n",
    "    keys = [k.strip() for k in keys]\n",
    "    for i in range(5):\n",
    "        values = f.readline().split('|')\n",
    "        values = [v.strip() for v in values]\n",
    "        d = dict(zip(keys,values))\n",
    "        data.append(d)\n",
    "data[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using [CSV](https://docs.python.org/3/library/csv.html) module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Fatima', 'email': 'Quisque.varius@Integervitae.org', 'birthdate': '11-25-01'}\n",
      "{'name': 'Katelyn', 'email': 'mi.pede.nonummy@Sedid.ca', 'birthdate': '11-27-03'}\n",
      "{'name': 'Gillian', 'email': 'odio.semper@sodalesMaurisblandit.org', 'birthdate': '02-19-14'}\n",
      "{'name': 'Preston', 'email': 'faucibus.orci@lacusQuisque.edu', 'birthdate': '08-07-09'}\n",
      "{'name': 'Priscilla', 'email': 'semper.auctor@cursusvestibulum.co.uk', 'birthdate': '08-12-01'}\n",
      "{'name': 'Zena', 'email': 'ante@magnaPraesent.com', 'birthdate': '11-24-11'}\n",
      "{'name': 'Oren', 'email': 'rutrum.eu.ultrices@nec.org', 'birthdate': '01-12-07'}\n",
      "{'name': 'Jamalia', 'email': 'Phasellus.vitae.mauris@vel.org', 'birthdate': '05-17-17'}\n",
      "{'name': 'Libby', 'email': 'velit.eu@Maecenasmi.edu', 'birthdate': '07-29-17'}\n",
      "{'name': 'Finn', 'email': 'natoque.penatibus@lectusa.net', 'birthdate': '06-23-10'}\n",
      "{'name': 'Graiden', 'email': 'neque.Nullam@hendreritidante.com', 'birthdate': '09-18-10'}\n",
      "{'name': 'Kitra', 'email': 'quis.tristique@estmollis.com', 'birthdate': '11-18-02'}\n",
      "{'name': 'Baxter', 'email': 'vitae.mauris@sed.org', 'birthdate': '04-12-17'}\n",
      "{'name': 'Margaret', 'email': 'ullamcorper@nec.ca', 'birthdate': '08-16-04'}\n",
      "{'name': 'Sopoline', 'email': 'vitae.diam@velitQuisquevarius.co.uk', 'birthdate': '09-03-06'}\n",
      "{'name': 'Flynn', 'email': 'eget.varius@magnased.org', 'birthdate': '08-28-14'}\n",
      "{'name': 'Beck', 'email': 'arcu.et.pede@idblandit.co.uk', 'birthdate': '01-14-06'}\n",
      "{'name': 'Sheila', 'email': 'natoque.penatibus.et@mattis.com', 'birthdate': '09-01-20'}\n",
      "{'name': 'Francis', 'email': 'ligula.Aliquam@nullaatsem.ca', 'birthdate': '08-25-14'}\n",
      "{'name': 'Harrison', 'email': 'nec.urna@loremauctorquis.com', 'birthdate': '02-10-16'}\n",
      "{'name': 'Imogene', 'email': 'malesuada.id@nibh.com', 'birthdate': '04-19-03'}\n",
      "{'name': 'Moana', 'email': 'sit@Morbinequetellus.net', 'birthdate': '07-05-03'}\n",
      "{'name': 'Kamal', 'email': 'pede.Nunc.sed@Proindolor.ca', 'birthdate': '01-14-01'}\n",
      "{'name': 'Fiona', 'email': 'nulla.at@Sedmalesuadaaugue.net', 'birthdate': '02-07-01'}\n",
      "{'name': 'Yuri', 'email': 'pharetra@cursuspurusNullam.edu', 'birthdate': '12-03-19'}\n",
      "{'name': 'Nichole', 'email': 'aliquet@euenim.org', 'birthdate': '04-06-03'}\n",
      "{'name': 'Irma', 'email': 'elit@pedeCras.net', 'birthdate': '04-29-18'}\n",
      "{'name': 'Leilani', 'email': 'et.ultrices@semegestasblandit.edu', 'birthdate': '10-25-14'}\n",
      "{'name': 'Rashad', 'email': 'imperdiet.nec@convallisligulaDonec.co.uk', 'birthdate': '02-09-11'}\n",
      "{'name': 'Jerry', 'email': 'augue@imperdiet.edu', 'birthdate': '08-28-02'}\n",
      "{'name': 'Thomas', 'email': 'mauris@utodio.com', 'birthdate': '09-30-10'}\n",
      "{'name': 'Yvette', 'email': 'ligula@Aliquam.edu', 'birthdate': '03-03-04'}\n",
      "{'name': 'Hashim', 'email': 'Integer.sem@pede.co.uk', 'birthdate': '07-29-07'}\n",
      "{'name': 'Theodore', 'email': 'ut.pharetra@egetipsumDonec.org', 'birthdate': '08-11-05'}\n",
      "{'name': 'Basil', 'email': 'facilisis.vitae@Curae.ca', 'birthdate': '08-31-15'}\n",
      "{'name': 'Blythe', 'email': 'lacinia@vehiculaPellentesquetincidunt.co.uk', 'birthdate': '10-05-02'}\n",
      "{'name': 'Suki', 'email': 'Suspendisse.commodo.tincidunt@velit.co.uk', 'birthdate': '04-17-07'}\n",
      "{'name': 'Mia', 'email': 'vulputate.velit@etmagnisdis.org', 'birthdate': '08-03-07'}\n",
      "{'name': 'Chastity', 'email': 'venenatis.lacus.Etiam@quisurna.edu', 'birthdate': '12-07-05'}\n",
      "{'name': 'Natalie', 'email': 'at.libero@feugiatplacerat.org', 'birthdate': '06-25-14'}\n",
      "{'name': 'Scarlet', 'email': 'ac.fermentum@ullamcorpereu.edu', 'birthdate': '09-13-00'}\n",
      "{'name': 'Gage', 'email': 'dolor.Fusce@ametlorem.edu', 'birthdate': '03-25-20'}\n",
      "{'name': 'Miranda', 'email': 'auctor.nunc@magnisdis.ca', 'birthdate': '09-20-02'}\n",
      "{'name': 'Nicole', 'email': 'elit@egestasSed.co.uk', 'birthdate': '09-08-15'}\n",
      "{'name': 'Tatyana', 'email': 'nec.urna@sagittis.co.uk', 'birthdate': '09-24-12'}\n",
      "{'name': 'Marcia', 'email': 'consectetuer@fringilla.co.uk', 'birthdate': '05-12-19'}\n",
      "{'name': 'Germaine', 'email': 'eget.ipsum@dui.ca', 'birthdate': '09-08-04'}\n",
      "{'name': 'Keith', 'email': 'Sed.et@nisimagna.net', 'birthdate': '12-20-05'}\n",
      "{'name': 'Zephr', 'email': 'Praesent.interdum.ligula@eu.edu', 'birthdate': '06-17-17'}\n",
      "{'name': 'Preston', 'email': 'accumsan.convallis.ante@sociisnatoquepenatibus.ca', 'birthdate': '08-30-08'}\n",
      "{'name': 'Stone', 'email': 'elit.sed@leoinlobortis.ca', 'birthdate': '09-30-02'}\n",
      "{'name': 'Phelan', 'email': 'Nam.ligula.elit@Sedpharetra.ca', 'birthdate': '03-29-02'}\n",
      "{'name': 'Colton', 'email': 'risus.Donec@blanditcongueIn.co.uk', 'birthdate': '04-28-11'}\n",
      "{'name': 'Stuart', 'email': 'senectus.et.netus@sit.com', 'birthdate': '03-24-09'}\n",
      "{'name': 'Brendan', 'email': 'enim.mi.tempor@nectempusscelerisque.edu', 'birthdate': '09-16-20'}\n",
      "{'name': 'Eden', 'email': 'velit.egestas.lacinia@non.com', 'birthdate': '07-13-04'}\n",
      "{'name': 'Geoffrey', 'email': 'Donec.egestas@ullamcorperDuis.co.uk', 'birthdate': '11-02-11'}\n",
      "{'name': 'Xantha', 'email': 'libero.at.auctor@mauris.ca', 'birthdate': '09-17-00'}\n",
      "{'name': 'Dylan', 'email': 'primis.in.faucibus@tortorIntegeraliquam.net', 'birthdate': '08-25-20'}\n",
      "{'name': 'Claire', 'email': 'pede@sagittissemperNam.ca', 'birthdate': '05-23-13'}\n",
      "{'name': 'Hayden', 'email': 'sed@Nam.org', 'birthdate': '02-24-09'}\n",
      "{'name': 'Russell', 'email': 'laoreet@infaucibus.net', 'birthdate': '03-06-04'}\n",
      "{'name': 'Ingrid', 'email': 'tincidunt.nibh@disparturient.co.uk', 'birthdate': '12-23-05'}\n",
      "{'name': 'Michael', 'email': 'orci.consectetuer@porttitorscelerisqueneque.com', 'birthdate': '06-30-18'}\n",
      "{'name': 'Elton', 'email': 'sem.molestie.sodales@vitaesemperegestas.edu', 'birthdate': '03-07-01'}\n",
      "{'name': 'Zena', 'email': 'sed@malesuadamalesuadaInteger.net', 'birthdate': '12-23-14'}\n",
      "{'name': 'Emi', 'email': 'dictum.eu@lorem.org', 'birthdate': '06-15-02'}\n",
      "{'name': 'Walter', 'email': 'non@loremacrisus.edu', 'birthdate': '08-27-08'}\n",
      "{'name': 'Jason', 'email': 'scelerisque.dui@maurissitamet.net', 'birthdate': '08-30-19'}\n",
      "{'name': 'Shannon', 'email': 'elit@sempercursus.net', 'birthdate': '10-31-13'}\n",
      "{'name': 'Seth', 'email': 'Aliquam.nec@eu.ca', 'birthdate': '10-30-09'}\n",
      "{'name': 'Magee', 'email': 'dui@odiosagittis.com', 'birthdate': '11-01-02'}\n",
      "{'name': 'Kasper', 'email': 'Praesent@Proinvel.edu', 'birthdate': '08-02-18'}\n",
      "{'name': 'Chester', 'email': 'et@orciPhasellus.org', 'birthdate': '11-04-07'}\n",
      "{'name': 'Cadman', 'email': 'a.sollicitudin@enimconsequat.com', 'birthdate': '12-03-15'}\n",
      "{'name': 'Erich', 'email': 'ligula.eu@sociosquadlitora.org', 'birthdate': '10-07-06'}\n",
      "{'name': 'Allegra', 'email': 'lorem@Suspendisse.edu', 'birthdate': '02-05-08'}\n",
      "{'name': 'Quemby', 'email': 'Curae.Donec@imperdietnonvestibulum.co.uk', 'birthdate': '09-28-06'}\n",
      "{'name': 'Beverly', 'email': 'ullamcorper@temporeratneque.net', 'birthdate': '11-17-08'}\n",
      "{'name': 'Kylee', 'email': 'luctus.felis.purus@variusultrices.net', 'birthdate': '01-16-04'}\n",
      "{'name': 'Aidan', 'email': 'Curae@sempereratin.net', 'birthdate': '10-15-08'}\n",
      "{'name': 'India', 'email': 'luctus@et.com', 'birthdate': '08-03-02'}\n",
      "{'name': 'Asher', 'email': 'dictum.Proin@in.edu', 'birthdate': '07-02-07'}\n",
      "{'name': 'Illana', 'email': 'interdum.libero@sitamet.com', 'birthdate': '08-05-21'}\n",
      "{'name': 'Maxine', 'email': 'enim.commodo.hendrerit@consequat.com', 'birthdate': '08-04-02'}\n",
      "{'name': 'Rashad', 'email': 'convallis.in@dapibusquam.org', 'birthdate': '07-19-20'}\n",
      "{'name': 'Pearl', 'email': 'facilisis.Suspendisse@arcuMorbi.co.uk', 'birthdate': '05-13-10'}\n",
      "{'name': 'Yael', 'email': 'facilisis.eget.ipsum@placerat.edu', 'birthdate': '09-19-17'}\n",
      "{'name': 'Michael', 'email': 'facilisi.Sed@consequat.co.uk', 'birthdate': '07-08-21'}\n",
      "{'name': 'Lawrence', 'email': 'luctus.Curabitur@lectusantedictum.ca', 'birthdate': '06-02-09'}\n",
      "{'name': 'Raja', 'email': 'et.rutrum@orciinconsequat.edu', 'birthdate': '02-13-11'}\n",
      "{'name': 'Irene', 'email': 'fermentum@maurisut.com', 'birthdate': '09-03-02'}\n",
      "{'name': 'Perry', 'email': 'velit@Pellentesqueut.co.uk', 'birthdate': '09-30-08'}\n",
      "{'name': 'Kellie', 'email': 'elit.Curabitur@erat.net', 'birthdate': '07-08-02'}\n",
      "{'name': 'Quemby', 'email': 'sed@sedest.ca', 'birthdate': '07-09-15'}\n",
      "{'name': 'Adrienne', 'email': 'Sed@faucibus.edu', 'birthdate': '03-06-01'}\n",
      "{'name': 'Quintessa', 'email': 'Aliquam.adipiscing@urna.org', 'birthdate': '08-21-07'}\n",
      "{'name': 'Baxter', 'email': 'blandit.at.nisi@Donec.edu', 'birthdate': '01-15-01'}\n",
      "{'name': 'Rylee', 'email': 'at@cursus.net', 'birthdate': '07-12-16'}\n",
      "{'name': 'Keegan', 'email': 'eu.lacus.Quisque@Inscelerisquescelerisque.net', 'birthdate': '12-23-05'}\n"
     ]
    }
   ],
   "source": [
    "with open(datafile, \"r\") as f:\n",
    "    #data2 = csv.reader(f, delimiter='|')\n",
    "    data2 = csv.DictReader(f, delimiter='|')\n",
    "    for row in data2:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>email</th>\n",
       "      <th>birthdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fatima</td>\n",
       "      <td>Quisque.varius@Integervitae.org</td>\n",
       "      <td>11-25-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Katelyn</td>\n",
       "      <td>mi.pede.nonummy@Sedid.ca</td>\n",
       "      <td>11-27-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gillian</td>\n",
       "      <td>odio.semper@sodalesMaurisblandit.org</td>\n",
       "      <td>02-19-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Preston</td>\n",
       "      <td>faucibus.orci@lacusQuisque.edu</td>\n",
       "      <td>08-07-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Priscilla</td>\n",
       "      <td>semper.auctor@cursusvestibulum.co.uk</td>\n",
       "      <td>08-12-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name                                 email birthdate\n",
       "0     Fatima       Quisque.varius@Integervitae.org  11-25-01\n",
       "1    Katelyn              mi.pede.nonummy@Sedid.ca  11-27-03\n",
       "2    Gillian  odio.semper@sodalesMaurisblandit.org  02-19-14\n",
       "3    Preston        faucibus.orci@lacusQuisque.edu  08-07-09\n",
       "4  Priscilla  semper.auctor@cursusvestibulum.co.uk  08-12-01"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv = pd.read_csv(datafile, sep=\"|\")\n",
    "df_csv.head()\n",
    "#df_csv.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating [Zip Files](https://docs.python.org/3/library/zipfile.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressedfile = \"2013_ERCOT_Hourly_Load_Data.zip\"\n",
    "datafile = os.path.join(datapath, compressedfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2013_ERCOT_Hourly_Load_Data.xls']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hour_End</th>\n",
       "      <th>COAST</th>\n",
       "      <th>EAST</th>\n",
       "      <th>FAR_WEST</th>\n",
       "      <th>NORTH</th>\n",
       "      <th>NORTH_C</th>\n",
       "      <th>SOUTHERN</th>\n",
       "      <th>SOUTH_C</th>\n",
       "      <th>WEST</th>\n",
       "      <th>ERCOT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01 01:00:00</td>\n",
       "      <td>7606.263544</td>\n",
       "      <td>1073.892438</td>\n",
       "      <td>1411.750567</td>\n",
       "      <td>784.978166</td>\n",
       "      <td>10369.094390</td>\n",
       "      <td>2206.675077</td>\n",
       "      <td>4368.490945</td>\n",
       "      <td>882.931901</td>\n",
       "      <td>28704.077028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01 02:00:00</td>\n",
       "      <td>7388.082714</td>\n",
       "      <td>1035.021938</td>\n",
       "      <td>1403.472287</td>\n",
       "      <td>776.307387</td>\n",
       "      <td>10152.358518</td>\n",
       "      <td>2159.733208</td>\n",
       "      <td>4233.587967</td>\n",
       "      <td>872.404750</td>\n",
       "      <td>28020.968769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01 03:00:00</td>\n",
       "      <td>7178.867878</td>\n",
       "      <td>1036.088697</td>\n",
       "      <td>1395.053150</td>\n",
       "      <td>768.125748</td>\n",
       "      <td>9988.051418</td>\n",
       "      <td>2065.114706</td>\n",
       "      <td>4082.862860</td>\n",
       "      <td>868.853938</td>\n",
       "      <td>27383.018395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-01 04:00:00</td>\n",
       "      <td>7038.822581</td>\n",
       "      <td>1032.648841</td>\n",
       "      <td>1395.508820</td>\n",
       "      <td>770.937969</td>\n",
       "      <td>9946.658655</td>\n",
       "      <td>1990.903699</td>\n",
       "      <td>4010.489608</td>\n",
       "      <td>865.701201</td>\n",
       "      <td>27051.671374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-01 05:00:00</td>\n",
       "      <td>6990.857940</td>\n",
       "      <td>1042.823044</td>\n",
       "      <td>1401.216842</td>\n",
       "      <td>779.089313</td>\n",
       "      <td>10096.664190</td>\n",
       "      <td>1954.807585</td>\n",
       "      <td>4038.655997</td>\n",
       "      <td>879.924249</td>\n",
       "      <td>27184.039160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Hour_End        COAST         EAST     FAR_WEST       NORTH  \\\n",
       "0 2013-01-01 01:00:00  7606.263544  1073.892438  1411.750567  784.978166   \n",
       "1 2013-01-01 02:00:00  7388.082714  1035.021938  1403.472287  776.307387   \n",
       "2 2013-01-01 03:00:00  7178.867878  1036.088697  1395.053150  768.125748   \n",
       "3 2013-01-01 04:00:00  7038.822581  1032.648841  1395.508820  770.937969   \n",
       "4 2013-01-01 05:00:00  6990.857940  1042.823044  1401.216842  779.089313   \n",
       "\n",
       "        NORTH_C     SOUTHERN      SOUTH_C        WEST         ERCOT  \n",
       "0  10369.094390  2206.675077  4368.490945  882.931901  28704.077028  \n",
       "1  10152.358518  2159.733208  4233.587967  872.404750  28020.968769  \n",
       "2   9988.051418  2065.114706  4082.862860  868.853938  27383.018395  \n",
       "3   9946.658655  1990.903699  4010.489608  865.701201  27051.671374  \n",
       "4  10096.664190  1954.807585  4038.655997  879.924249  27184.039160  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with ZipFile(datafile, 'r') as myzip:\n",
    "    print(myzip.namelist())\n",
    "    unzipped = myzip.namelist()[0]\n",
    "    with myzip.open(unzipped) as myfile:\n",
    "        pd_excel = pd.read_excel(myfile)\n",
    "        \n",
    "pd_excel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Acessing](https://pypi.python.org/pypi/xlrd) and [Writing](https://pypi.python.org/pypi/xlwt) [Excel Files](https://github.com/python-excel/tutorial/blob/master/python-excel.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!sudo pip install -U xlrd xlwt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing a workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile(datafile, 'r') as myzip:\n",
    "    unzipped = myzip.namelist()[0]\n",
    "    myzip.extractall(datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbook = xlrd.open_workbook(os.path.join(datapath, unzipped))\n",
    "sheet = workbook.sheet_by_index(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Hour_End',\n",
       "  'COAST',\n",
       "  'EAST',\n",
       "  'FAR_WEST',\n",
       "  'NORTH',\n",
       "  'NORTH_C',\n",
       "  'SOUTHERN',\n",
       "  'SOUTH_C',\n",
       "  'WEST',\n",
       "  'ERCOT'],\n",
       " [41275.041666666664,\n",
       "  7606.263544000012,\n",
       "  1073.892438,\n",
       "  1411.7505669999982,\n",
       "  784.9781659999992,\n",
       "  10369.094390000051,\n",
       "  2206.6750770000012,\n",
       "  4368.490945000006,\n",
       "  882.9319009999975,\n",
       "  28704.077028000065]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sheet_data = [[sheet.cell_value(r, col) for col in range(sheet.ncols)] for r in range(sheet.nrows)]\n",
    "sheet_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the sheet:\n",
      "7296\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows in the sheet:\"),\n",
    "print(sheet.nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of data in cell (row 3, col 2):\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(\"Type of data in cell (row 3, col 2):\"), \n",
    "print(sheet.cell_type(3, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value in cell (row 3, col 2):\n",
      "1036.0886969999988\n"
     ]
    }
   ],
   "source": [
    "print(\"Value in cell (row 3, col 2):\", )\n",
    "print(sheet.cell_value(3, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get a slice of values in column 3, from rows 1-3:\n",
      "[1411.7505669999982, 1403.4722870000019, 1395.053150000001]\n"
     ]
    }
   ],
   "source": [
    "print(\"Get a slice of values in column 3, from rows 1-3:\",)\n",
    "print(sheet.col_values(3, start_rowx=1, end_rowx=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "coast = sheet.col_values(1, start_rowx=1)\n",
    "data3 = {}    \n",
    "data3['maxvalue'] = max(coast)\n",
    "data3['minvalue'] = min(coast)\n",
    "data3['avgcoast'] = np.mean(coast)\n",
    "\n",
    "rowmax = coast.index(max(coast))+1\n",
    "rowmin = coast.index(min(coast))+1\n",
    "\n",
    "data3['maxtime'] = xlrd.xldate_as_tuple(sheet.cell_value(rowmax,0), 0)\n",
    "data3['mintime'] = xlrd.xldate_as_tuple(sheet.cell_value(rowmin,0), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'maxvalue': 18779.025510000003,\n",
       " 'minvalue': 6602.113898999982,\n",
       " 'avgcoast': 10976.933460679784,\n",
       " 'maxtime': (2013, 8, 13, 17, 0, 0),\n",
       " 'mintime': (2013, 2, 3, 4, 0, 0)}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_excel.html  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hour_End</th>\n",
       "      <th>COAST</th>\n",
       "      <th>EAST</th>\n",
       "      <th>FAR_WEST</th>\n",
       "      <th>NORTH</th>\n",
       "      <th>NORTH_C</th>\n",
       "      <th>SOUTHERN</th>\n",
       "      <th>SOUTH_C</th>\n",
       "      <th>WEST</th>\n",
       "      <th>ERCOT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01 01:00:00</td>\n",
       "      <td>7606.263544</td>\n",
       "      <td>1073.892438</td>\n",
       "      <td>1411.750567</td>\n",
       "      <td>784.978166</td>\n",
       "      <td>10369.094390</td>\n",
       "      <td>2206.675077</td>\n",
       "      <td>4368.490945</td>\n",
       "      <td>882.931901</td>\n",
       "      <td>28704.077028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01 02:00:00</td>\n",
       "      <td>7388.082714</td>\n",
       "      <td>1035.021938</td>\n",
       "      <td>1403.472287</td>\n",
       "      <td>776.307387</td>\n",
       "      <td>10152.358518</td>\n",
       "      <td>2159.733208</td>\n",
       "      <td>4233.587967</td>\n",
       "      <td>872.404750</td>\n",
       "      <td>28020.968769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01 03:00:00</td>\n",
       "      <td>7178.867878</td>\n",
       "      <td>1036.088697</td>\n",
       "      <td>1395.053150</td>\n",
       "      <td>768.125748</td>\n",
       "      <td>9988.051418</td>\n",
       "      <td>2065.114706</td>\n",
       "      <td>4082.862860</td>\n",
       "      <td>868.853938</td>\n",
       "      <td>27383.018395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-01 04:00:00</td>\n",
       "      <td>7038.822581</td>\n",
       "      <td>1032.648841</td>\n",
       "      <td>1395.508820</td>\n",
       "      <td>770.937969</td>\n",
       "      <td>9946.658655</td>\n",
       "      <td>1990.903699</td>\n",
       "      <td>4010.489608</td>\n",
       "      <td>865.701201</td>\n",
       "      <td>27051.671374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-01 05:00:00</td>\n",
       "      <td>6990.857940</td>\n",
       "      <td>1042.823044</td>\n",
       "      <td>1401.216842</td>\n",
       "      <td>779.089313</td>\n",
       "      <td>10096.664190</td>\n",
       "      <td>1954.807585</td>\n",
       "      <td>4038.655997</td>\n",
       "      <td>879.924249</td>\n",
       "      <td>27184.039160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Hour_End        COAST         EAST     FAR_WEST       NORTH  \\\n",
       "0 2013-01-01 01:00:00  7606.263544  1073.892438  1411.750567  784.978166   \n",
       "1 2013-01-01 02:00:00  7388.082714  1035.021938  1403.472287  776.307387   \n",
       "2 2013-01-01 03:00:00  7178.867878  1036.088697  1395.053150  768.125748   \n",
       "3 2013-01-01 04:00:00  7038.822581  1032.648841  1395.508820  770.937969   \n",
       "4 2013-01-01 05:00:00  6990.857940  1042.823044  1401.216842  779.089313   \n",
       "\n",
       "        NORTH_C     SOUTHERN      SOUTH_C        WEST         ERCOT  \n",
       "0  10369.094390  2206.675077  4368.490945  882.931901  28704.077028  \n",
       "1  10152.358518  2159.733208  4233.587967  872.404750  28020.968769  \n",
       "2   9988.051418  2065.114706  4082.862860  868.853938  27383.018395  \n",
       "3   9946.658655  1990.903699  4010.489608  865.701201  27051.671374  \n",
       "4  10096.664190  1954.807585  4038.655997  879.924249  27184.039160  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_excel = pd.read_excel(os.path.join(datapath, unzipped))\n",
    "pd_excel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#erasing file\n",
    "os.remove(os.path.join(datapath, unzipped))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading and Writing a Workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlwt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "style0 = xlwt.easyxf('font: name Times New Roman, color-index red, bold on', num_format_str='#,##0.00')\n",
    "style1 = xlwt.easyxf(num_format_str='D-MMM-YY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbook = xlwt.Workbook()\n",
    "workbook_name = 'my_workbook.xls'\n",
    "\n",
    "worksheet1 = workbook.add_sheet('my_first_sheet')\n",
    "worksheet1.write(0, 0, 'Column 1 title', style0)\n",
    "worksheet1.write(0, 1, 'Column 2 title', style0)\n",
    "\n",
    "worksheet2 = workbook.add_sheet('my_second_sheet')\n",
    "worksheet2.write(0, 0, 'Itens')\n",
    "worksheet2.write(0, 1, 'Price')\n",
    "worksheet2.write(1, 0, 'Rice')\n",
    "worksheet2.write(1, 1, 100)\n",
    "worksheet2.write(2, 0, 'Beans')\n",
    "worksheet2.write(2, 1, 200)\n",
    "worksheet2.write(3, 0, 'Pasta')\n",
    "worksheet2.write(3, 1, 500)\n",
    "worksheet2.write(5, 0, 'Total')\n",
    "\n",
    "worksheet2.write(5, 1, xlwt.Formula(\"B2+B3+B4\"))\n",
    "\n",
    "\n",
    "workbook.save(os.path.join(datapath, workbook_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#erasing file\n",
    "os.remove(os.path.join(datapath, workbook_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading PDF Files  \n",
    "\n",
    "More resources [here](https://textract.readthedocs.io/en/stable/) and [here](https://towardsdatascience.com/python-for-pdf-ef0fac2808b0?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!sudo pip install -U textract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in the folder:\n",
      "0 -- RobertFrost_Poetry.pdf\n"
     ]
    }
   ],
   "source": [
    "onlyfiles = [f for f in os.listdir(datapath) if os.path.isfile(os.path.join(datapath, f)) and f.endswith('.pdf')]\n",
    "onlyfiles.sort()\n",
    "\n",
    "print('Files in the folder:')\n",
    "for i, w in enumerate(onlyfiles):\n",
    "    print(i, '--' ,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classic Poetry Series\n",
      "\n",
      "Robert Frost\n",
      "- poems -\n",
      "\n",
      "Publication Date:\n",
      "2004\n",
      "\n",
      "Publisher:\n",
      "\n",
      "PoemHunter.Com - The World's Poetry Archive\n",
      "\n",
      "\f",
      "\"In White\": Frost's Early Version Of Design\n",
      "A dented spider like a snow drop white\n",
      "On a white Heal-all, holding up a moth\n",
      "Like a white piece of lifeless satin cloth Saw ever curious eye so strange a sight? Portent in little, assorted death and blight\n",
      "Like the ingredients of a witches' broth? The beady spider, the flower like a froth,\n",
      "And the moth carried like a paper kite.\n",
      "\n",
      "What had that flower to do with being white,\n",
      "The blue prunella every child's delight.\n",
      "What brought the kindred spider to that height?\n",
      "(Make we no thesis of the miller's plight.)\n",
      "What but design of darkness and of night?\n",
      "Design, design! Do I use the word aright?\n",
      "Anonymous submission.\n",
      "Robert Frost\n",
      "\n",
      "www.PoemHunter.com - The World's Poetry Archive\n",
      "\n",
      "2\n",
      "\n",
      "\f",
      "A Boundless Moment\n",
      "He halted in the wind, and -- what was that\n",
      "Far in the maples, pale, but not a ghost?\n",
      "He stood there bringing March against \n"
     ]
    }
   ],
   "source": [
    "text0 = textract.process(os.path.join(datapath, onlyfiles[0])).decode('utf-8')\n",
    "print(text0[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Text in Image Files (OCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sudo apt install -y tesseract-ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in the folder:\n",
      "0 -- 1 HgrHDlU85dKtyLonNgu2zA.png\n",
      "1 -- SQLAlchemyORM.png\n",
      "2 -- db_schema.png\n",
      "3 -- textimage.png\n"
     ]
    }
   ],
   "source": [
    "onlyfiles = [f for f in os.listdir(datapath) if os.path.isfile(os.path.join(datapath, f)) and f.endswith('.png')]\n",
    "onlyfiles.sort()\n",
    "\n",
    "print('Files in the folder:')\n",
    "for i, w in enumerate(onlyfiles):\n",
    "    print(i, '--' ,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adobe, the Adobe logo, Acrobat, the Acrobat logo, Acrobat Capture, Adobe Garamond, Adobe\n",
      "Intelligent Document Platform, Adobe PDF, Adobe Reader, Adobe Solutions Network, Aldus, Dis-\n",
      "tiller, ePaper, Extreme, FrameMaker, Illustrator, InDesign, Minion, Myriad, PageMaker, Photo-\n",
      "shop, Poetica, PostScript, and XMP are either registered trademarks or trademarks of Adobe\n",
      "â€˜Systems Incorporated in the United States and/or other countries. Microsoft and Windows are\n",
      "either registered trademarks or trademarks of Microsoft Corporation in the United States and/or\n",
      "other countries. Apple, Mac, Macintosh, and Power Macintosh are trademarks of Apple Computer,\n",
      "Inc,, registered in the United States and other countries. IBM is a registered trademark of IBM\n",
      "Corporation in the United States. Sun is a trademark or registered trademark of Sun Microsys-\n",
      "tems, Inc. in the United States and other countries. UNIX is\n"
     ]
    }
   ],
   "source": [
    "text1 = textract.process(os.path.join(datapath, onlyfiles[3])).decode('utf-8')\n",
    "\n",
    "print(text1[0:900])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.python.org/3/library/urllib.html  \n",
    "http://www.crummy.com/software/BeautifulSoup/  \n",
    "http://docs.python-requests.org/en/latest/  \n",
    "http://lxml.de/  \n",
    "https://docs.python.org/3/library/getpass.html  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import lxml.html\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " '#mw-head',\n",
       " '#searchInput',\n",
       " '/wiki/Ficheiro:Guimar%C3%A3es_Rosa,_anos_1960.tif',\n",
       " '/wiki/Arquivo_Nacional_(Brasil)',\n",
       " '/wiki/27_de_junho#Nascimentos',\n",
       " '/wiki/1908',\n",
       " '/wiki/Cordisburgo',\n",
       " '/wiki/Minas_Gerais',\n",
       " '/wiki/19_de_novembro']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://pt.wikipedia.org/wiki/Guimar%C3%A3es_Rosa\"\n",
    "html_txt = urllib.request.urlopen(url).read()\n",
    "soup = bs(html_txt, \"html.parser\")\n",
    " \n",
    "[line.get('href') for line in soup.find_all('a')][0:10]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another approach: [lxml](http://lxml.de/tutorial.html) instead of beautiful soup\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#mw-head',\n",
       " '#searchInput',\n",
       " '/wiki/Ficheiro:Guimar%C3%A3es_Rosa,_anos_1960.tif',\n",
       " '/wiki/Arquivo_Nacional_(Brasil)',\n",
       " '/wiki/27_de_junho#Nascimentos',\n",
       " '/wiki/1908',\n",
       " '/wiki/Cordisburgo',\n",
       " '/wiki/Minas_Gerais',\n",
       " '/wiki/19_de_novembro',\n",
       " '/wiki/1967']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://pt.wikipedia.org/wiki/Guimar%C3%A3es_Rosa\"\n",
    "html_txt = urllib.request.urlopen(url).read()\n",
    "dom =  lxml.html.fromstring(html_txt)\n",
    "    \n",
    "[line for line in dom.xpath('//a/@href')][0:10]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using [Requests](http://docs.python-requests.org/en/master/user/quickstart/), for more complex tasks  \n",
    "\n",
    "\n",
    "c.f. [HTML Responses](http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = getpass.getpass()\n",
    "r = requests.get('https://api.github.com/user', auth=('rsouza', p))\n",
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'application/json; charset=utf-8'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.headers['content-type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'utf-8'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"login\":\"rsouza\",\"id\":604914,\"node_id\":\"MDQ6VXNlcjYwNDkxNA==\",\"avatar_url\":\"https://avatars0.githubusercontent.com/u/604914?v=4\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/rsouza\",\"html_url\":\"https://github.com/rsouza\",\"followers_url\":\"https://api.github.com/users/rsouza/followers\",\"following_url\":\"https://api.github.com/users/rsouza/following{/other_user}\",\"gists_url\":\"https://api.github.com/users/rsouza/gists{/gist_id}\",\"starred_url\":\"https://api.github.com/users/rsouza/starred{/owner}{/repo}\",\"subscriptions_url\":\"https://api.github.com/users/rsouza/subscriptions\",\"organizations_url\":\"https://api.github.com/users/rsouza/orgs\",\"repos_url\":\"https://api.github.com/users/rsouza/repos\",\"events_url\":\"https://api.github.com/users/rsouza/events{/privacy}\",\"received_events_url\":\"https://api.github.com/users/rsouza/received_events\",\"type\":\"User\",\"site_admin\":false,\"name\":\"Renato Rocha Souza\",\"company\":\"Ã–AW ACDH-CH | FGV | UFMG\",\"blog\":\"https://www.oeaw.ac.at/acdh/team/current-team/renato-souza/\",\"location\":\"Viena\",\"email\":\"rsouza.fgv@gmail.com\",\"hireable\":null,\"bio\":\"\\\\r\\\\n    https://www.linkedin.com/in/renato-rocha-souza-157153\\\\r\\\\n\",\"twitter_username\":\"rrsouza\",\"public_repos\":49,\"public_gists\":3,\"followers\":118,\"following\":9,\"created_at\":\"2011-02-07T15:46:45Z\",\"updated_at\":\"2020-11-10T21:04:39Z\",\"private_gists\":0,\"total_private_repos\":2,\"owned_private_repos\":1,\"disk_usage\":1240543,\"collaborators\":2,\"two_factor_authentication\":false,\"plan\":{\"name\":\"free\",\"space\":976562499,\"collaborators\":0,\"private_repos\":10000}}'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'login': 'rsouza',\n",
       " 'id': 604914,\n",
       " 'node_id': 'MDQ6VXNlcjYwNDkxNA==',\n",
       " 'avatar_url': 'https://avatars0.githubusercontent.com/u/604914?v=4',\n",
       " 'gravatar_id': '',\n",
       " 'url': 'https://api.github.com/users/rsouza',\n",
       " 'html_url': 'https://github.com/rsouza',\n",
       " 'followers_url': 'https://api.github.com/users/rsouza/followers',\n",
       " 'following_url': 'https://api.github.com/users/rsouza/following{/other_user}',\n",
       " 'gists_url': 'https://api.github.com/users/rsouza/gists{/gist_id}',\n",
       " 'starred_url': 'https://api.github.com/users/rsouza/starred{/owner}{/repo}',\n",
       " 'subscriptions_url': 'https://api.github.com/users/rsouza/subscriptions',\n",
       " 'organizations_url': 'https://api.github.com/users/rsouza/orgs',\n",
       " 'repos_url': 'https://api.github.com/users/rsouza/repos',\n",
       " 'events_url': 'https://api.github.com/users/rsouza/events{/privacy}',\n",
       " 'received_events_url': 'https://api.github.com/users/rsouza/received_events',\n",
       " 'type': 'User',\n",
       " 'site_admin': False,\n",
       " 'name': 'Renato Rocha Souza',\n",
       " 'company': 'Ã–AW ACDH-CH | FGV | UFMG',\n",
       " 'blog': 'https://www.oeaw.ac.at/acdh/team/current-team/renato-souza/',\n",
       " 'location': 'Viena',\n",
       " 'email': 'rsouza.fgv@gmail.com',\n",
       " 'hireable': None,\n",
       " 'bio': '\\r\\n    https://www.linkedin.com/in/renato-rocha-souza-157153\\r\\n',\n",
       " 'twitter_username': 'rrsouza',\n",
       " 'public_repos': 49,\n",
       " 'public_gists': 3,\n",
       " 'followers': 118,\n",
       " 'following': 9,\n",
       " 'created_at': '2011-02-07T15:46:45Z',\n",
       " 'updated_at': '2020-11-10T21:04:39Z',\n",
       " 'private_gists': 0,\n",
       " 'total_private_repos': 2,\n",
       " 'owned_private_repos': 1,\n",
       " 'disk_usage': 1240543,\n",
       " 'collaborators': 2,\n",
       " 'two_factor_authentication': False,\n",
       " 'plan': {'name': 'free',\n",
       "  'space': 976562499,\n",
       "  'collaborators': 0,\n",
       "  'private_repos': 10000}}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing [JSON](http://json.org/)\n",
    "\n",
    "https://docs.python.org/3/library/json.html  \n",
    "https://docs.python.org/3/library/urllib.html  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"http://musicbrainz.org/ws/2/\"\n",
    "artist_url =  urllib.parse.urljoin(base_url, 'artist/')\n",
    "query_type = {\"simple\": {},\n",
    "              \"atr\": {\"inc\": \"aliases+tags+ratings\"},\n",
    "              \"aliases\": {\"inc\": \"aliases\"},\n",
    "              \"releases\": {\"inc\": \"releases\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_site(url, params, uid=\"\", fmt=\"json\"):\n",
    "    params[\"fmt\"] = fmt\n",
    "    r = requests.get(url + uid, params=params)\n",
    "    print(\"requesting\", r.url)\n",
    "\n",
    "    if r.status_code == requests.codes.ok:\n",
    "        return r.json()\n",
    "    else:\n",
    "        r.raise_for_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_by_name(url, params, name):\n",
    "    params[\"query\"] = \"artist:\" + name\n",
    "    return query_site(url, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print(data, indent=4):\n",
    "    if type(data) == dict:\n",
    "        print(json.dumps(data, indent=indent, sort_keys=True))\n",
    "    else:\n",
    "        print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requesting http://musicbrainz.org/ws/2/artist/?query=artist%3ANirvana&fmt=json\n",
      "[{'id': '5b11f4ce-a62d-471e-81fc-a69a8278c7da', 'type': 'Group', 'type-id': 'e431f5f6-b5d2-343d-8b36-72607fffb74b', 'score': 100, 'name': 'Nirvana', 'sort-name': 'Nirvana', 'country': 'US', 'area': {'id': '489ce91b-6658-3307-9877-795b68554c98', 'type': 'Country', 'type-id': '06dd0ae4-8c74-30bb-b43d-95dcedf961de', 'name': 'United States', 'sort-name': 'United States', 'life-span': {'ended': None}}, 'begin-area': {'id': 'a640b45c-c173-49b1-8030-973603e895b5', 'type': 'City', 'type-id': '6fd8f29a-3d0a-32fc-980d-ea697b69da78', 'name': 'Aberdeen', 'sort-name': 'Aberdeen', 'life-span': {'ended': None}}, 'disambiguation': '90s US grunge band', 'isnis': ['0000000123486830', '0000000123487390'], 'life-span': {'begin': '1988-01', 'end': '1994-04-05', 'ended': True}, 'aliases': [{'sort-name': 'ãƒ‹ãƒ«ãƒ´ã‚¡ãƒ¼ãƒŠ', 'type-id': '894afba6-2816-3c24-8072-eadb66bd04bc', 'name': 'ãƒ‹ãƒ«ãƒ´ã‚¡ãƒ¼ãƒŠ', 'locale': 'ja', 'type': 'Artist name', 'primary': True, 'begin-date': None, 'end-date': None}, {'sort-name': 'Nirvana US', 'name': 'Nirvana US', 'locale': None, 'type': None, 'primary': None, 'begin-date': None, 'end-date': None}, {'sort-name': 'Nirvana', 'type-id': '894afba6-2816-3c24-8072-eadb66bd04bc', 'name': 'Nirvana', 'locale': 'en', 'type': 'Artist name', 'primary': True, 'begin-date': None, 'end-date': None}], 'tags': [{'count': 2, 'name': 'usa'}, {'count': 0, 'name': 'united states'}, {'count': 0, 'name': 'northwest'}, {'count': 27, 'name': 'grunge'}, {'count': 11, 'name': 'alternative rock'}, {'count': 0, 'name': '90'}, {'count': 8, 'name': 'american'}, {'count': 0, 'name': 'amÃ©ricain'}, {'count': 0, 'name': 'alternative'}, {'count': 2, 'name': '90s'}, {'count': 1, 'name': 'acoustic rock'}, {'count': 0, 'name': 'nirvana'}, {'count': 2, 'name': 'noise rock'}, {'count': 17, 'name': 'rock'}, {'count': 0, 'name': 'band'}, {'count': 0, 'name': 'legendary'}, {'count': 0, 'name': 'kurt cobain'}, {'count': 0, 'name': 'rock and indie'}, {'count': 2, 'name': 'punk'}, {'count': 3, 'name': 'seattle'}, {'count': 2, 'name': 'experimental'}]}, {'id': '9282c8b4-ca0b-4c6b-b7e3-4f7762dfc4d6', 'type': 'Group', 'type-id': 'e431f5f6-b5d2-343d-8b36-72607fffb74b', 'score': 79, 'name': 'Nirvana', 'sort-name': 'Nirvana', 'country': 'GB', 'area': {'id': '8a754a16-0027-3a29-b6d7-2b40ea0481ed', 'type': 'Country', 'type-id': '06dd0ae4-8c74-30bb-b43d-95dcedf961de', 'name': 'United Kingdom', 'sort-name': 'United Kingdom', 'life-span': {'ended': None}}, 'begin-area': {'id': 'f03d09b3-39dc-4083-afd6-159e3f0d462f', 'type': 'City', 'type-id': '6fd8f29a-3d0a-32fc-980d-ea697b69da78', 'name': 'London', 'sort-name': 'London', 'life-span': {'ended': None}}, 'disambiguation': '60s band from the UK', 'life-span': {'begin': '1967', 'ended': None}, 'tags': [{'count': 1, 'name': 'english'}, {'count': 1, 'name': 'british'}, {'count': 2, 'name': 'progressive rock'}, {'count': 2, 'name': 'rock'}, {'count': 1, 'name': 'power pop'}, {'count': 1, 'name': 'soft rock'}, {'count': 1, 'name': 'pop'}, {'count': 1, 'name': 'psychedelic rock'}, {'count': 1, 'name': 'pop rock'}, {'count': 1, 'name': 'symphonic rock'}, {'count': 0, 'name': 'orchestral'}, {'count': 1, 'name': 'psychedelic pop'}, {'count': 1, 'name': 'baroque pop'}]}, {'id': 'c3a64a25-251b-4d03-afba-1471440245b8', 'type': 'Group', 'type-id': 'e431f5f6-b5d2-343d-8b36-72607fffb74b', 'score': 74, 'name': 'Approaching Nirvana', 'sort-name': 'Approaching Nirvana', 'country': 'US', 'area': {'id': '489ce91b-6658-3307-9877-795b68554c98', 'type': 'Country', 'type-id': '06dd0ae4-8c74-30bb-b43d-95dcedf961de', 'name': 'United States', 'sort-name': 'United States', 'life-span': {'ended': None}}, 'life-span': {'begin': '2009', 'ended': None}}, {'id': 'c49d69dc-e008-47cf-b5ff-160fafb1fe1f', 'type': 'Group', 'type-id': 'e431f5f6-b5d2-343d-8b36-72607fffb74b', 'score': 71, 'name': 'Nirvana', 'sort-name': 'Nirvana', 'country': 'FR', 'area': {'id': '08310658-51eb-3801-80de-5a0739207115', 'type': 'Country', 'type-id': '06dd0ae4-8c74-30bb-b43d-95dcedf961de', 'name': 'France', 'sort-name': 'France', 'life-span': {'ended': None}}, 'disambiguation': 'â€™70s French band from Martigues', 'life-span': {'ended': None}}, {'id': '85af0709-95db-4fbc-801a-120e9f4766d0', 'type': 'Group', 'type-id': 'e431f5f6-b5d2-343d-8b36-72607fffb74b', 'score': 70, 'name': 'Nirvana', 'sort-name': 'Nirvana', 'country': 'FI', 'area': {'id': '6a264f94-6ff1-30b1-9a81-41f7bfabd616', 'type': 'Country', 'type-id': '06dd0ae4-8c74-30bb-b43d-95dcedf961de', 'name': 'Finland', 'sort-name': 'Finland', 'life-span': {'ended': None}}, 'disambiguation': \"Early 1980's Finnish punk band\", 'life-span': {'ended': None}, 'tags': [{'count': 1, 'name': 'finland'}, {'count': 1, 'name': 'punk'}]}, {'id': '28a4618c-38e4-4027-ad2c-db66a14a2d85', 'type': 'Group', 'type-id': 'e431f5f6-b5d2-343d-8b36-72607fffb74b', 'score': 70, 'name': 'Nirvana', 'sort-name': 'Nirvana', 'country': 'YU', 'area': {'id': '885dce63-c211-3033-8cf7-46cb82d440c7', 'type': 'Country', 'type-id': '06dd0ae4-8c74-30bb-b43d-95dcedf961de', 'name': 'Yugoslavia', 'sort-name': 'Yugoslavia', 'life-span': {'begin': '1918', 'end': '2003', 'ended': True}}, 'disambiguation': 'Croatian prog-rock band active in first half of 70s in former Yugoslavia.', 'life-span': {'ended': None}}, {'id': '3aa878c0-224b-41e5-abd1-63be359d2bca', 'score': 70, 'name': 'Nirvana', 'sort-name': 'Nirvana', 'disambiguation': 'founded in 1987 by a Michael Jackson double/imitator', 'life-span': {'begin': '1987', 'ended': None}}, {'id': 'f2dfdff9-3862-4be0-bf85-9c833fa3059e', 'type': 'Group', 'type-id': 'e431f5f6-b5d2-343d-8b36-72607fffb74b', 'score': 63, 'name': 'Nirvana 2002', 'sort-name': 'Nirvana 2002', 'country': 'SE', 'area': {'id': '23d10872-f5ae-3f0c-bf55-332788a16ecb', 'type': 'Country', 'type-id': '06dd0ae4-8c74-30bb-b43d-95dcedf961de', 'name': 'Sweden', 'sort-name': 'Sweden', 'life-span': {'ended': None}}, 'disambiguation': 'Swedish death metal band', 'life-span': {'begin': '1988', 'end': '2012', 'ended': True}, 'aliases': [{'sort-name': 'Prophet 2002', 'name': 'Prophet 2002', 'locale': None, 'type': None, 'primary': None, 'begin-date': '1988', 'end-date': '1988'}, {'sort-name': 'Nirvana', 'name': 'Nirvana', 'locale': None, 'type': None, 'primary': None, 'begin-date': '1988', 'end-date': '1988'}, {'sort-name': 'N2K2', 'name': 'N2K2', 'locale': None, 'type': None, 'primary': None, 'begin-date': None, 'end-date': None}]}, {'id': '329c04ae-3b73-4ca3-996f-75608ab1befb', 'type': 'Person', 'type-id': 'b6e035f4-3ce9-331c-97df-83397230b0df', 'score': 62, 'name': 'Nirvana Singh', 'sort-name': 'Singh, Nirvana', 'life-span': {'ended': None}}, {'id': '89e9ed9d-9b45-42ad-bce2-54ef36053a1a', 'type': 'Group', 'type-id': 'e431f5f6-b5d2-343d-8b36-72607fffb74b', 'score': 62, 'name': 'Nirvana Seekerz', 'sort-name': 'Nirvana Seekerz', 'life-span': {'ended': None}}, {'id': '86f9ae24-ba2a-4d55-9275-0b89b85f6e3a', 'score': 62, 'name': 'Weed Nirvana', 'sort-name': 'Weed Nirvana', 'life-span': {'ended': None}}, {'id': 'b305320e-c158-43f4-b5be-4450e2f99a32', 'score': 62, 'name': 'El Nirvana', 'sort-name': 'Nirvana, El', 'life-span': {'ended': None}}, {'id': '206419e0-3a7a-49ce-8437-4e757767d02b', 'type': 'Person', 'type-id': 'b6e035f4-3ce9-331c-97df-83397230b0df', 'score': 62, 'name': 'Nirvana Savoury', 'sort-name': 'Savoury, Nirvana', 'gender': 'female', 'country': 'US', 'area': {'id': '489ce91b-6658-3307-9877-795b68554c98', 'type': 'Country', 'type-id': '06dd0ae4-8c74-30bb-b43d-95dcedf961de', 'name': 'United States', 'sort-name': 'United States', 'life-span': {'ended': None}}, 'life-span': {'ended': None}}, {'id': '7c525bf4-abf0-42e3-a1bd-81cbcb55c1f4', 'score': 61, 'name': 'Genta Nirvana', 'sort-name': 'Genta Nirvana', 'country': 'ID', 'area': {'id': 'd3a68bd0-7419-3f99-a5bd-204d6e057089', 'type': 'Country', 'type-id': '06dd0ae4-8c74-30bb-b43d-95dcedf961de', 'name': 'Indonesia', 'sort-name': 'Indonesia', 'life-span': {'ended': None}}, 'disambiguation': 'experimental', 'life-span': {'ended': None}}, {'id': '74ba0d66-e029-4b2e-9bd2-627b0febdc1d', 'score': 61, 'name': 'Cheick Nirvana', 'sort-name': 'Cheick Nirvana', 'life-span': {'ended': None}}, {'id': 'da77e424-c473-481e-a2ae-5d966b2ee0b6', 'type': 'Group', 'type-id': 'e431f5f6-b5d2-343d-8b36-72607fffb74b', 'score': 61, 'name': 'Nirvana Undercover', 'sort-name': 'Nirvana Undercover', 'begin-area': {'id': 'ef1b7cc0-cd26-36f4-8ea0-04d9623786c7', 'type': 'Country', 'type-id': '06dd0ae4-8c74-30bb-b43d-95dcedf961de', 'name': 'Netherlands', 'sort-name': 'Netherlands', 'life-span': {'ended': None}}, 'life-span': {'ended': None}}, {'id': '8f32371e-4bac-4090-ba13-2c1cd1aeab0d', 'type': 'Group', 'type-id': 'e431f5f6-b5d2-343d-8b36-72607fffb74b', 'score': 61, 'name': 'Nirvana UK', 'sort-name': 'Nirvana UK', 'area': {'id': '07607044-8140-47ba-bb24-7129babe586b', 'type': 'Subdivision', 'type-id': 'fd3d44c5-80a1-3842-9745-2c4972d35afa', 'name': 'West Midlands', 'sort-name': 'West Midlands', 'life-span': {'ended': None}}, 'life-span': {'ended': None}}, {'id': 'f58febd3-18de-4371-8d95-4a68d4f79456', 'type': 'Person', 'type-id': 'b6e035f4-3ce9-331c-97df-83397230b0df', 'score': 61, 'name': 'Nirvana Kelly', 'sort-name': 'Kelly, Nirvana', 'life-span': {'ended': None}}, {'id': 'e43ad11b-5d29-45ae-90f7-73ac47fb815d', 'score': 56, 'name': 'smells like nirvana', 'sort-name': 'smells like nirvana', 'life-span': {'ended': None}}, {'id': '45eacd92-6857-4faa-9283-023e72a1d4b1', 'type': 'Group', 'type-id': 'e431f5f6-b5d2-343d-8b36-72607fffb74b', 'score': 56, 'name': 'The Nirvana Experience', 'sort-name': 'The Nirvana Experience', 'area': {'id': 'c920948b-83e3-40b7-8fe9-9ab5abaac55b', 'type': 'City', 'type-id': '6fd8f29a-3d0a-32fc-980d-ea697b69da78', 'name': 'Houston', 'sort-name': 'Houston', 'life-span': {'ended': None}}, 'begin-area': {'id': 'c920948b-83e3-40b7-8fe9-9ab5abaac55b', 'type': 'City', 'type-id': '6fd8f29a-3d0a-32fc-980d-ea697b69da78', 'name': 'Houston', 'sort-name': 'Houston', 'life-span': {'ended': None}}, 'disambiguation': 'Nirvana Cover Band', 'life-span': {'begin': '2012', 'ended': None}}, {'id': '1d512080-0ef7-454f-a325-9bf5ff95ce88', 'type': 'Group', 'type-id': 'e431f5f6-b5d2-343d-8b36-72607fffb74b', 'score': 56, 'name': 'Come As Nirvana', 'sort-name': 'Come As Nirvana', 'country': 'BE', 'area': {'id': '5b8a5ee5-0bb3-34cf-9a75-c27c44e341fc', 'type': 'Country', 'type-id': '06dd0ae4-8c74-30bb-b43d-95dcedf961de', 'name': 'Belgium', 'sort-name': 'Belgium', 'life-span': {'ended': None}}, 'disambiguation': 'Belgian', 'life-span': {'ended': None}}, {'id': '46d8dae4-abec-438b-9c62-a3dbb2aaa1b7', 'type': 'Group', 'type-id': 'e431f5f6-b5d2-343d-8b36-72607fffb74b', 'score': 56, 'name': 'Nirvana Teen Spirit', 'sort-name': 'Nirvana Teen Spirit', 'area': {'id': 'e8ad73e9-9e7f-41c4-a395-6e29260ff1df', 'type': 'City', 'type-id': '6fd8f29a-3d0a-32fc-980d-ea697b69da78', 'name': 'Graz', 'sort-name': 'Graz', 'life-span': {'ended': None}}, 'begin-area': {'id': 'e8ad73e9-9e7f-41c4-a395-6e29260ff1df', 'type': 'City', 'type-id': '6fd8f29a-3d0a-32fc-980d-ea697b69da78', 'name': 'Graz', 'sort-name': 'Graz', 'life-span': {'ended': None}}, 'disambiguation': 'Nirvana-Coverband', 'life-span': {'begin': '2000', 'ended': None}}, {'id': '02c4e6bb-7b7a-4686-8c23-df01bfd42b0e', 'type': 'Group', 'type-id': 'e431f5f6-b5d2-343d-8b36-72607fffb74b', 'score': 56, 'name': 'Sappy Nirvana Tribute', 'sort-name': 'Sappy Nirvana Tribute', 'area': {'id': 'c621114d-73cc-4832-8afe-f13dc261e5af', 'type': 'City', 'type-id': '6fd8f29a-3d0a-32fc-980d-ea697b69da78', 'name': 'Gatineau', 'sort-name': 'Gatineau', 'life-span': {'ended': None}}, 'begin-area': {'id': 'c621114d-73cc-4832-8afe-f13dc261e5af', 'type': 'City', 'type-id': '6fd8f29a-3d0a-32fc-980d-ea697b69da78', 'name': 'Gatineau', 'sort-name': 'Gatineau', 'life-span': {'ended': None}}, 'life-span': {'begin': '2012-04-05', 'ended': None}}, {'id': 'bb94730d-22c2-422d-a0a7-fe16a5b3e429', 'type': 'Group', 'type-id': 'e431f5f6-b5d2-343d-8b36-72607fffb74b', 'score': 52, 'name': 'The Attainment of Nirvana', 'sort-name': 'Attainment of Nirvana, The', 'life-span': {'ended': None}}, {'id': 'e1388435-f80d-434a-9980-f1c9f5aa9b90', 'score': 48, 'name': 'Nirvana Sitar & String Group', 'sort-name': 'Nirvana Sitar & String Group', 'life-span': {'ended': None}}]\n"
     ]
    }
   ],
   "source": [
    "results = query_by_name(artist_url, query_type[\"simple\"], \"Nirvana\")\n",
    "pretty_print(results['artists'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['created', 'count', 'offset', 'artists'])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ARTIST:\n",
      "{\n",
      "    \"area\": {\n",
      "        \"id\": \"6a264f94-6ff1-30b1-9a81-41f7bfabd616\",\n",
      "        \"life-span\": {\n",
      "            \"ended\": null\n",
      "        },\n",
      "        \"name\": \"Finland\",\n",
      "        \"sort-name\": \"Finland\",\n",
      "        \"type\": \"Country\",\n",
      "        \"type-id\": \"06dd0ae4-8c74-30bb-b43d-95dcedf961de\"\n",
      "    },\n",
      "    \"country\": \"FI\",\n",
      "    \"disambiguation\": \"Early 1980's Finnish punk band\",\n",
      "    \"id\": \"85af0709-95db-4fbc-801a-120e9f4766d0\",\n",
      "    \"life-span\": {\n",
      "        \"ended\": null\n",
      "    },\n",
      "    \"name\": \"Nirvana\",\n",
      "    \"score\": 70,\n",
      "    \"sort-name\": \"Nirvana\",\n",
      "    \"tags\": [\n",
      "        {\n",
      "            \"count\": 1,\n",
      "            \"name\": \"finland\"\n",
      "        },\n",
      "        {\n",
      "            \"count\": 1,\n",
      "            \"name\": \"punk\"\n",
      "        }\n",
      "    ],\n",
      "    \"type\": \"Group\",\n",
      "    \"type-id\": \"e431f5f6-b5d2-343d-8b36-72607fffb74b\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nARTIST:\")\n",
    "pretty_print(results[\"artists\"][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'85af0709-95db-4fbc-801a-120e9f4766d0'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist_id = results[\"artists\"][4][\"id\"]\n",
    "artist_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requesting http://musicbrainz.org/ws/2/artist/85af0709-95db-4fbc-801a-120e9f4766d0?inc=releases&fmt=json\n",
      "\n",
      "ONE RELEASE:\n",
      "{\n",
      "  \"barcode\": \"\",\n",
      "  \"country\": \"FI\",\n",
      "  \"date\": \"1980\",\n",
      "  \"disambiguation\": \"\",\n",
      "  \"id\": \"3e25396c-5c66-4609-8e47-37f250d323c7\",\n",
      "  \"packaging\": \"Cardboard/Paper Sleeve\",\n",
      "  \"packaging-id\": \"f7101ce3-0384-39ce-9fde-fbbd0044d35f\",\n",
      "  \"quality\": \"normal\",\n",
      "  \"release-events\": [\n",
      "    {\n",
      "      \"area\": {\n",
      "        \"disambiguation\": \"\",\n",
      "        \"id\": \"6a264f94-6ff1-30b1-9a81-41f7bfabd616\",\n",
      "        \"iso-3166-1-codes\": [\n",
      "          \"FI\"\n",
      "        ],\n",
      "        \"name\": \"Finland\",\n",
      "        \"sort-name\": \"Finland\",\n",
      "        \"type\": null,\n",
      "        \"type-id\": null\n",
      "      },\n",
      "      \"date\": \"1980\"\n",
      "    }\n",
      "  ],\n",
      "  \"status\": \"Official\",\n",
      "  \"status-id\": \"4e304316-386d-3409-af2e-78857eec5cfe\",\n",
      "  \"text-representation\": {\n",
      "    \"language\": \"fin\",\n",
      "    \"script\": \"Latn\"\n",
      "  },\n",
      "  \"title\": \"Nirvana\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "artist_data = query_site(artist_url, query_type[\"releases\"], artist_id)\n",
    "releases = artist_data[\"releases\"]\n",
    "print(\"\\nONE RELEASE:\")\n",
    "pretty_print(releases[0], indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'date': '1980',\n",
       "  'id': '3e25396c-5c66-4609-8e47-37f250d323c7',\n",
       "  'packaging-id': 'f7101ce3-0384-39ce-9fde-fbbd0044d35f',\n",
       "  'barcode': '',\n",
       "  'title': 'Nirvana',\n",
       "  'text-representation': {'script': 'Latn', 'language': 'fin'},\n",
       "  'status-id': '4e304316-386d-3409-af2e-78857eec5cfe',\n",
       "  'quality': 'normal',\n",
       "  'packaging': 'Cardboard/Paper Sleeve',\n",
       "  'status': 'Official',\n",
       "  'disambiguation': '',\n",
       "  'release-events': [{'area': {'disambiguation': '',\n",
       "     'type': None,\n",
       "     'iso-3166-1-codes': ['FI'],\n",
       "     'sort-name': 'Finland',\n",
       "     'name': 'Finland',\n",
       "     'id': '6a264f94-6ff1-30b1-9a81-41f7bfabd616',\n",
       "     'type-id': None},\n",
       "    'date': '1980'}],\n",
       "  'country': 'FI'}]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "releases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ALL TITLES:\n",
      "Nirvana\n"
     ]
    }
   ],
   "source": [
    "release_titles = [r[\"title\"] for r in releases]\n",
    "print(\"\\nALL TITLES:\")\n",
    "for t in release_titles:\n",
    "        print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://pandas.pydata.org/pandas-docs/stable/io.html#io-json-reader  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 26 columns):\n",
      " #   Column                    Non-Null Count  Dtype              \n",
      "---  ------                    --------------  -----              \n",
      " 0   url                       5 non-null      object             \n",
      " 1   repository_url            5 non-null      object             \n",
      " 2   labels_url                5 non-null      object             \n",
      " 3   comments_url              5 non-null      object             \n",
      " 4   events_url                5 non-null      object             \n",
      " 5   html_url                  5 non-null      object             \n",
      " 6   id                        5 non-null      int64              \n",
      " 7   node_id                   5 non-null      object             \n",
      " 8   number                    5 non-null      int64              \n",
      " 9   title                     5 non-null      object             \n",
      " 10  user                      5 non-null      object             \n",
      " 11  labels                    5 non-null      object             \n",
      " 12  state                     5 non-null      object             \n",
      " 13  locked                    5 non-null      bool               \n",
      " 14  assignee                  0 non-null      float64            \n",
      " 15  assignees                 5 non-null      object             \n",
      " 16  milestone                 0 non-null      float64            \n",
      " 17  comments                  5 non-null      int64              \n",
      " 18  created_at                5 non-null      datetime64[ns, UTC]\n",
      " 19  updated_at                5 non-null      datetime64[ns, UTC]\n",
      " 20  closed_at                 0 non-null      datetime64[ns]     \n",
      " 21  author_association        5 non-null      object             \n",
      " 22  active_lock_reason        0 non-null      float64            \n",
      " 23  body                      5 non-null      object             \n",
      " 24  performed_via_github_app  0 non-null      float64            \n",
      " 25  pull_request              4 non-null      object             \n",
      "dtypes: bool(1), datetime64[ns, UTC](2), datetime64[ns](1), float64(4), int64(3), object(15)\n",
      "memory usage: 1.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_json = pd.read_json('https://api.github.com/repos/pydata/pandas/issues?per_page=5')\n",
    "df_json.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing YAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'martin': {'name': \"Martin D'vloper\", 'job': 'Developer', 'skills': ['python', 'perl', 'pascal']}}, {'tabitha': {'name': 'Tabitha Bitumen', 'job': 'Developer', 'skills': ['lisp', 'fortran', 'erlang']}}]\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(datapath, 'simple.yaml'), 'r') as stream:\n",
    "    try:\n",
    "        yamlfile = yaml.load(stream, Loader=yaml.Loader)\n",
    "        print(yamlfile)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>martin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>job</th>\n",
       "      <td>Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>Martin D'vloper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skills</th>\n",
       "      <td>[python, perl, pascal]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        martin\n",
       "job                  Developer\n",
       "name           Martin D'vloper\n",
       "skills  [python, perl, pascal]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(yamlfile[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing XML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.python.org/3/library/urllib.html\n",
    "\n",
    "https://docs.python.org/3/library/xml.etree.elementtree.html\n",
    "\n",
    "http://lxml.de/\n",
    "\n",
    "http://www.w3schools.com/xml/xml_examples.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.dom import minidom\n",
    "#from xml.etree import ElementTree as ET\n",
    "from lxml import etree as ET #Supports xpath syntax\n",
    "from collections import defaultdict\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.w3schools.com/xml/cd_catalog.xml'\n",
    "xml_page = urllib.request.urlopen(url).read()\n",
    "e = ET.XML(xml_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etree_to_dict(t):\n",
    "    d = {t.tag: {} if t.attrib else None}\n",
    "    children = list(t)\n",
    "    if children:\n",
    "        dd = defaultdict(list)\n",
    "        for dc in map(etree_to_dict, children):\n",
    "            for k, v in dc.items():\n",
    "                dd[k].append(v)\n",
    "        d = {t.tag: {k:v[0] if len(v) == 1 else v for k, v in dd.items()}}\n",
    "    if t.attrib:\n",
    "        d[t.tag].update(('@' + k, v) for k, v in t.attrib.items())\n",
    "    if t.text:\n",
    "        text = t.text.strip()\n",
    "        if children or t.attrib:\n",
    "            if text:\n",
    "              d[t.tag]['#text'] = text\n",
    "        else:\n",
    "            d[t.tag] = text\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CATALOG': {'CD': [{'ARTIST': 'Bob Dylan',\n",
      "                     'COMPANY': 'Columbia',\n",
      "                     'COUNTRY': 'USA',\n",
      "                     'PRICE': '10.90',\n",
      "                     'TITLE': 'Empire Burlesque',\n",
      "                     'YEAR': '1985'},\n",
      "                    {'ARTIST': 'Bonnie Tyler',\n",
      "                     'COMPANY': 'CBS Records',\n",
      "                     'COUNTRY': 'UK',\n",
      "                     'PRICE': '9.90',\n",
      "                     'TITLE': 'Hide your heart',\n",
      "                     'YEAR': '1988'},\n",
      "                    {'ARTIST': 'Dolly Parton',\n",
      "                     'COMPANY': 'RCA',\n",
      "                     'COUNTRY': 'USA',\n",
      "                     'PRICE': '9.90',\n",
      "                     'TITLE': 'Greatest Hits',\n",
      "                     'YEAR': '1982'},\n",
      "                    {'ARTIST': 'Gary Moore',\n",
      "                     'COMPANY': 'Virgin records',\n",
      "                     'COUNTRY': 'UK',\n",
      "                     'PRICE': '10.20',\n",
      "                     'TITLE': 'Still got the blues',\n",
      "                     'YEAR': '1990'},\n",
      "                    {'ARTIST': 'Eros Ramazzotti',\n",
      "                     'COMPANY': 'BMG',\n",
      "                     'COUNTRY': 'EU',\n",
      "                     'PRICE': '9.90',\n",
      "                     'TITLE': 'Eros',\n",
      "                     'YEAR': '1997'},\n",
      "                    {'ARTIST': 'Bee Gees',\n",
      "                     'COMPANY': 'Polydor',\n",
      "                     'COUNTRY': 'UK',\n",
      "                     'PRICE': '10.90',\n",
      "                     'TITLE': 'One night only',\n",
      "                     'YEAR': '1998'},\n",
      "                    {'ARTIST': 'Dr.Hook',\n",
      "                     'COMPANY': 'CBS',\n",
      "                     'COUNTRY': 'UK',\n",
      "                     'PRICE': '8.10',\n",
      "                     'TITLE': 'Sylvias Mother',\n",
      "                     'YEAR': '1973'},\n",
      "                    {'ARTIST': 'Rod Stewart',\n",
      "                     'COMPANY': 'Pickwick',\n",
      "                     'COUNTRY': 'UK',\n",
      "                     'PRICE': '8.50',\n",
      "                     'TITLE': 'Maggie May',\n",
      "                     'YEAR': '1990'},\n",
      "                    {'ARTIST': 'Andrea Bocelli',\n",
      "                     'COMPANY': 'Polydor',\n",
      "                     'COUNTRY': 'EU',\n",
      "                     'PRICE': '10.80',\n",
      "                     'TITLE': 'Romanza',\n",
      "                     'YEAR': '1996'},\n",
      "                    {'ARTIST': 'Percy Sledge',\n",
      "                     'COMPANY': 'Atlantic',\n",
      "                     'COUNTRY': 'USA',\n",
      "                     'PRICE': '8.70',\n",
      "                     'TITLE': 'When a man loves a woman',\n",
      "                     'YEAR': '1987'},\n",
      "                    {'ARTIST': 'Savage Rose',\n",
      "                     'COMPANY': 'Mega',\n",
      "                     'COUNTRY': 'EU',\n",
      "                     'PRICE': '10.90',\n",
      "                     'TITLE': 'Black angel',\n",
      "                     'YEAR': '1995'},\n",
      "                    {'ARTIST': 'Many',\n",
      "                     'COMPANY': 'Grammy',\n",
      "                     'COUNTRY': 'USA',\n",
      "                     'PRICE': '10.20',\n",
      "                     'TITLE': '1999 Grammy Nominees',\n",
      "                     'YEAR': '1999'},\n",
      "                    {'ARTIST': 'Kenny Rogers',\n",
      "                     'COMPANY': 'Mucik Master',\n",
      "                     'COUNTRY': 'UK',\n",
      "                     'PRICE': '8.70',\n",
      "                     'TITLE': 'For the good times',\n",
      "                     'YEAR': '1995'},\n",
      "                    {'ARTIST': 'Will Smith',\n",
      "                     'COMPANY': 'Columbia',\n",
      "                     'COUNTRY': 'USA',\n",
      "                     'PRICE': '9.90',\n",
      "                     'TITLE': 'Big Willie style',\n",
      "                     'YEAR': '1997'},\n",
      "                    {'ARTIST': 'Van Morrison',\n",
      "                     'COMPANY': 'Polydor',\n",
      "                     'COUNTRY': 'UK',\n",
      "                     'PRICE': '8.20',\n",
      "                     'TITLE': 'Tupelo Honey',\n",
      "                     'YEAR': '1971'},\n",
      "                    {'ARTIST': 'Jorn Hoel',\n",
      "                     'COMPANY': 'WEA',\n",
      "                     'COUNTRY': 'Norway',\n",
      "                     'PRICE': '7.90',\n",
      "                     'TITLE': 'Soulsville',\n",
      "                     'YEAR': '1996'},\n",
      "                    {'ARTIST': 'Cat Stevens',\n",
      "                     'COMPANY': 'Island',\n",
      "                     'COUNTRY': 'UK',\n",
      "                     'PRICE': '8.90',\n",
      "                     'TITLE': 'The very best of',\n",
      "                     'YEAR': '1990'},\n",
      "                    {'ARTIST': 'Sam Brown',\n",
      "                     'COMPANY': 'A and M',\n",
      "                     'COUNTRY': 'UK',\n",
      "                     'PRICE': '8.90',\n",
      "                     'TITLE': 'Stop',\n",
      "                     'YEAR': '1988'},\n",
      "                    {'ARTIST': \"T'Pau\",\n",
      "                     'COMPANY': 'Siren',\n",
      "                     'COUNTRY': 'UK',\n",
      "                     'PRICE': '7.90',\n",
      "                     'TITLE': 'Bridge of Spies',\n",
      "                     'YEAR': '1987'},\n",
      "                    {'ARTIST': 'Tina Turner',\n",
      "                     'COMPANY': 'Capitol',\n",
      "                     'COUNTRY': 'UK',\n",
      "                     'PRICE': '8.90',\n",
      "                     'TITLE': 'Private Dancer',\n",
      "                     'YEAR': '1983'},\n",
      "                    {'ARTIST': 'Kim Larsen',\n",
      "                     'COMPANY': 'Medley',\n",
      "                     'COUNTRY': 'EU',\n",
      "                     'PRICE': '7.80',\n",
      "                     'TITLE': 'Midt om natten',\n",
      "                     'YEAR': '1983'},\n",
      "                    {'ARTIST': 'Luciano Pavarotti',\n",
      "                     'COMPANY': 'DECCA',\n",
      "                     'COUNTRY': 'UK',\n",
      "                     'PRICE': '9.90',\n",
      "                     'TITLE': 'Pavarotti Gala Concert',\n",
      "                     'YEAR': '1991'},\n",
      "                    {'ARTIST': 'Otis Redding',\n",
      "                     'COMPANY': 'Stax Records',\n",
      "                     'COUNTRY': 'USA',\n",
      "                     'PRICE': '7.90',\n",
      "                     'TITLE': 'The dock of the bay',\n",
      "                     'YEAR': '1968'},\n",
      "                    {'ARTIST': 'Simply Red',\n",
      "                     'COMPANY': 'Elektra',\n",
      "                     'COUNTRY': 'EU',\n",
      "                     'PRICE': '7.20',\n",
      "                     'TITLE': 'Picture book',\n",
      "                     'YEAR': '1985'},\n",
      "                    {'ARTIST': 'The Communards',\n",
      "                     'COMPANY': 'London',\n",
      "                     'COUNTRY': 'UK',\n",
      "                     'PRICE': '7.80',\n",
      "                     'TITLE': 'Red',\n",
      "                     'YEAR': '1987'},\n",
      "                    {'ARTIST': 'Joe Cocker',\n",
      "                     'COMPANY': 'EMI',\n",
      "                     'COUNTRY': 'USA',\n",
      "                     'PRICE': '8.20',\n",
      "                     'TITLE': 'Unchain my heart',\n",
      "                     'YEAR': '1987'}]}}\n"
     ]
    }
   ],
   "source": [
    "pprint(etree_to_dict(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element node: CATALOG\n",
      "text node:\n",
      "  \n",
      "Element node: CD\n",
      "text node:\n",
      "    \n",
      "Element node: TITLE\n",
      "text node:Empire Burlesque\n",
      "text node:\n",
      "    \n",
      "Element node: ARTIST\n",
      "text node:Bob Dylan\n",
      "text node:\n",
      "    \n",
      "Element node: COUNTRY\n",
      "text node:USA\n",
      "text node:\n",
      "    \n",
      "Element node: COMPANY\n",
      "text node:Columbia\n",
      "text node:\n",
      "    \n",
      "Element node: PRICE\n",
      "text node:10.90\n",
      "text node:\n",
      "    \n",
      "Element node: YEAR\n",
      "text node:1985\n",
      "text node:\n",
      "  \n",
      "text node:\n",
      "  \n",
      "Element node: CD\n",
      "text node:\n",
      "    \n",
      "Element node: TITLE\n",
      "text node:Hide your heart\n",
      "text node:\n",
      "    \n",
      "Element node: ARTIST\n",
      "text node:Bonnie Tyler\n",
      "text node:\n",
      "    \n",
      "Element node: COUNTRY\n",
      "text node:UK\n",
      "text node:\n",
      "    \n",
      "Element node: COMPANY\n",
      "text node:CBS Records\n",
      "text node:\n",
      "    \n",
      "Element node: PRICE\n",
      "text node:9.90\n",
      "text node:\n",
      "    \n",
      "Element node: YEAR\n",
      "text node:1988\n",
      "text node:\n",
      "  \n",
      "text node:\n",
      "  \n",
      "Element node: CD\n",
      "text node:\n",
      "    \n",
      "Element node: TITLE\n",
      "text node:Greatest Hits\n",
      "text node:\n",
      "    \n",
      "Element node: ARTIST\n",
      "text node:Dolly Parton\n",
      "text node:\n",
      "    \n",
      "Element node: COUNTRY\n",
      "text node:USA\n",
      "text node:\n",
      "    \n",
      "Element node: COMPANY\n",
      "text node:RCA\n",
      "text node:\n",
      "    \n",
      "Element node: PRICE\n",
      "text node:9.90\n",
      "text node:\n",
      "    \n",
      "Element node: YEAR\n",
      "text node:1982\n",
      "text node:\n",
      "  \n",
      "text node:\n",
      "  \n",
      "Element node: CD\n",
      "text node:\n",
      "    \n",
      "Element node: TITLE\n",
      "text node:Still got the blues\n",
      "text node:\n",
      "    \n",
      "Element node: ARTIST\n",
      "text node:Gary Moore\n",
      "text node:\n",
      "    \n",
      "Element node: COUNTRY\n",
      "text node:UK\n",
      "text node:\n",
      "    \n",
      "Element node: COMPANY\n",
      "text node:Virgin records\n",
      "text node:\n",
      "    \n",
      "Element node: PRICE\n",
      "text node:10.20\n",
      "text node:\n",
      "    \n",
      "Element node: YEAR\n",
      "text node:1990\n",
      "text node:\n",
      "  \n",
      "text node:\n",
      "  \n",
      "Element node: CD\n",
      "text node:\n",
      "    \n",
      "Element node: TITLE\n",
      "text node:Eros\n",
      "text node:\n",
      "    \n",
      "Element node: ARTIST\n",
      "text node:Eros Ramazzotti\n",
      "text node:\n",
      "    \n",
      "Element node: COUNTRY\n",
      "text node:EU\n",
      "text node:\n",
      "    \n",
      "Element node: COMPANY\n",
      "text node:BMG\n",
      "text node:\n",
      "    \n",
      "Element node: PRICE\n",
      "text node:9.90\n",
      "text node:\n",
      "    \n",
      "Element node: YEAR\n",
      "text node:1997\n",
      "text node:\n",
      "  \n",
      "text node:\n",
      "  \n",
      "Element node: CD\n",
      "text node:\n",
      "    \n",
      "Element node: TITLE\n",
      "text node:One night only\n",
      "text node:\n",
      "    \n",
      "Element node: ARTIST\n",
      "text node:Bee Gees\n",
      "text node:\n",
      "    \n",
      "Element node: COUNTRY\n",
      "text node:UK\n",
      "text node:\n",
      "    \n",
      "Element node: COMPANY\n",
      "text node:Polydor\n",
      "text node:\n",
      "    \n",
      "Element node: PRICE\n",
      "text node:10.90\n",
      "text node:\n",
      "    \n",
      "Element node: YEAR\n",
      "text node:1998\n",
      "text node:\n",
      "  \n",
      "text node:\n",
      "  \n",
      "Element node: CD\n",
      "text node:\n",
      "    \n",
      "Element node: TITLE\n",
      "text node:Sylvias Mother\n",
      "text node:\n",
      "    \n",
      "Element node: ARTIST\n",
      "text node:Dr.Hook\n",
      "text node:\n",
      "    \n",
      "Element node: COUNTRY\n",
      "text node:UK\n",
      "text node:\n",
      "    \n",
      "Element node: COMPANY\n",
      "text node:CBS\n",
      "text node:\n",
      "    \n",
      "Element node: PRICE\n",
      "text node:8.10\n",
      "text node:\n",
      "    \n",
      "Element node: YEAR\n",
      "text node:1973\n",
      "text node:\n",
      "  \n",
      "text node:\n",
      "  \n",
      "Element node: CD\n",
      "text node:\n",
      "    \n",
      "Element node: TITLE\n",
      "text node:Maggie May\n",
      "text node:\n",
      "    \n",
      "Element node: ARTIST\n",
      "text node:Rod Stewart\n",
      "text node:\n",
      "    \n",
      "Element node: COUNTRY\n",
      "text node:UK\n",
      "text node:\n",
      "    \n",
      "Element node: COMPANY\n",
      "text node:Pickwick\n",
      "text node:\n",
      "    \n",
      "Element node: PRICE\n",
      "text node:8.50\n",
      "text node:\n",
      "    \n",
      "Element node: YEAR\n",
      "text node:1990\n",
      "text node:\n",
      "  \n",
      "text node:\n",
      "  \n",
      "Element node: CD\n",
      "text node:\n",
      "    \n",
      "Element node: TITLE\n",
      "text node:Romanza\n",
      "text node:\n",
      "    \n",
      "Element node: ARTIST\n",
      "text node:Andrea Bocelli\n",
      "text node:\n",
      "    \n",
      "Element node: COUNTRY\n",
      "text node:EU\n",
      "text node:\n",
      "    \n",
      "Element node: COMPANY\n",
      "text node:Polydor\n",
      "text node:\n",
      "    \n",
      "Element node: PRICE\n",
      "text node:10.80\n",
      "text node:\n",
      "    \n",
      "Element node: YEAR\n",
      "text node:1996\n",
      "text node:\n",
      "  \n",
      "text node:\n",
      "  \n",
      "Element node: CD\n",
      "text node:\n",
      "    \n",
      "Element node: TITLE\n",
      "text node:When a man loves a woman\n",
      "text node:\n",
      "    \n",
      "Element node: ARTIST\n",
      "text node:Percy Sledge\n",
      "text node:\n",
      "    \n",
      "Element node: COUNTRY\n",
      "text node:USA\n",
      "text node:\n",
      "    \n",
      "Element node: COMPANY\n",
      "text node:Atlantic\n",
      "text node:\n",
      "    \n",
      "Element node: PRICE\n",
      "text node:8.70\n",
      "text node:\n",
      "    \n",
      "Element node: YEAR\n",
      "text node:1987\n",
      "text node:\n",
      "  \n",
      "text node:\n",
      "  \n",
      "Element node: CD\n",
      "text node:\n",
      "    \n",
      "Element node: TITLE\n",
      "text node:Black angel\n",
      "text node:\n",
      "    \n",
      "Element node: ARTIST\n",
      "text node:Savage Rose\n",
      "text node:\n",
      "    \n",
      "Element node: COUNTRY\n",
      "text node:EU\n",
      "text node:\n",
      "    \n",
      "Element node: COMPANY\n",
      "text node:Mega\n",
      "text node:\n",
      "    \n",
      "Element node: PRICE\n",
      "text node:10.90\n",
      "text node:\n",
      "    \n",
      "Element node: YEAR\n",
      "text node:1995\n",
      "text node:\n",
      "  \n",
      "text node:\n",
      "  \n",
      "Element node: CD\n",
      "text node:\n",
      "    \n",
      "Element node: TITLE\n",
      "text node:1999 Grammy Nominees\n",
      "text node:\n",
      "    \n",
      "Element node: ARTIST\n",
      "text node:Many\n",
      "text node:\n",
      "    \n",
      "Element node: COUNTRY\n",
      "text node:USA\n",
      "text node:\n",
      "    \n",
      "Element node: COMPANY\n",
      "text node:Grammy\n",
      "text node:\n",
      "    \n",
      "Element node: PRICE\n",
      "text node:10.20\n",
      "text node:\n",
      "    \n",
      "Element node: YEAR\n",
      "text node:1999\n",
      "text node:\n",
      "  \n",
      "text node:\n",
      "  \n",
      "Element node: CD\n",
      "text node:\n",
      "    \n",
      "Element node: TITLE\n",
      "text node:For the good times\n",
      "text node:\n",
      "    \n",
      "Element node: ARTIST\n",
      "text node:Kenny Rogers\n",
      "text node:\n",
      "    \n",
      "Element node: COUNTRY\n",
      "text node:UK\n",
      "text node:\n",
      "    \n",
      "Element node: COMPANY\n",
      "text node:Mucik Master\n",
      "text node:\n",
      "    \n",
      "Element node: PRICE\n",
      "text node:8.70\n",
      "text node:\n",
      "    \n",
      "Element node: YEAR\n",
      "text node:1995\n",
      "text node:\n",
      "  \n",
      "text node:\n",
      "  \n",
      "Element node: CD\n",
      "text node:\n",
      "    \n",
      "Element node: TITLE\n",
      "text node:Big Willie style\n",
      "text node:\n",
      "    \n",
      "Element node: ARTIST\n",
      "text node:Will Smith\n",
      "text node:\n",
      "    \n",
      "Element node: COUNTRY\n",
      "text node:USA\n",
      "text node:\n",
      "    \n",
      "Element node: COMPANY\n",
      "text node:Columbia\n",
      "text node:\n",
      "    \n",
      "Element node: PRICE\n",
      "text node:9.90\n",
      "text node:\n",
      "    \n",
      "Element node: YEAR\n",
      "text node:1997\n",
      "text node:\n",
      "  \n",
      "text node:\n",
      "  \n",
      "Element node: CD\n",
      "text node:\n",
      "    \n",
      "Element node: TITLE\n",
      "text node:Tupelo Honey\n",
      "text node:\n",
      "    \n",
      "Element node: ARTIST\n",
      "text node:Van Morrison\n",
      "text node:\n",
      "    \n",
      "Element node: COUNTRY\n",
      "text node:UK\n",
      "text node:\n",
      "    \n",
      "Element node: COMPANY\n",
      "text node:Polydor\n",
      "text node:\n",
      "    \n",
      "Element node: PRICE\n",
      "text node:8.20\n",
      "text node:\n",
      "    \n",
      "Element node: YEAR\n",
      "text node:1971\n",
      "text node:\n",
      "  \n",
      "text node:\n",
      "  \n",
      "Element node: CD\n",
      "text node:\n",
      "    \n",
      "Element node: TITLE\n",
      "text node:Soulsville\n",
      "text node:\n",
      "    \n",
      "Element node: ARTIST\n",
      "text node:Jorn Hoel\n",
      "text node:\n",
      "    \n",
      "Element node: COUNTRY\n",
      "text node:Norway\n",
      "text node:\n",
      "    \n",
      "Element node: COMPANY\n",
      "text node:WEA\n",
      "text node:\n",
      "    \n",
      "Element node: PRICE\n",
      "text node:7.90\n",
      "text node:\n",
      "    \n",
      "Element node: YEAR\n",
      "text node:1996\n",
      "text node:\n",
      "  \n",
      "text node:\n",
      "  \n",
      "Element node: CD\n",
      "text node:\n",
      "    \n",
      "Element node: TITLE\n",
      "text node:The very best of\n",
      "text node:\n",
      "    \n",
      "Element node: ARTIST\n",
      "text node:Cat Stevens\n",
      "text node:\n",
      "    \n",
      "Element node: COUNTRY\n",
      "text node:UK\n",
      "text node:\n",
      "    \n",
      "Element node: COMPANY\n",
      "text node:Island\n",
      "text node:\n",
      "    \n",
      "Element node: PRICE\n",
      "text node:8.90\n",
      "text node:\n",
      "    \n",
      "Element node: YEAR\n",
      "text node:1990\n",
      "text node:\n",
      "  \n",
      "text node:\n",
      "  \n",
      "Element node: CD\n",
      "text node:\n",
      "    \n",
      "Element node: TITLE\n",
      "text node:Stop\n",
      "text node:\n",
      "    \n",
      "Element node: ARTIST\n",
      "text node:Sam Brown\n",
      "text node:\n",
      "    \n",
      "Element node: COUNTRY\n",
      "text node:UK\n",
      "text node:\n",
      "    \n",
      "Element node: COMPANY\n",
      "text node:A and M\n",
      "text node:\n",
      "    \n",
      "Element node: PRICE\n",
      "text node:8.90\n",
      "text node:\n",
      "    \n",
      "Element node: YEAR\n",
      "text node:1988\n",
      "text node:\n",
      "  \n",
      "text node:\n",
      "  \n",
      "Element node: CD\n",
      "text node:\n",
      "    \n",
      "Element node: TITLE\n",
      "text node:Bridge of Spies\n",
      "text node:\n",
      "    \n",
      "Element node: ARTIST\n",
      "text node:T'Pau\n",
      "text node:\n",
      "    \n",
      "Element node: COUNTRY\n",
      "text node:UK\n",
      "text node:\n",
      "    \n",
      "Element node: COMPANY\n",
      "text node:Siren\n",
      "text node:\n",
      "    \n",
      "Element node: PRICE\n",
      "text node:7.90\n",
      "text node:\n",
      "    \n",
      "Element node: YEAR\n",
      "text node:1987\n",
      "text node:\n",
      "  \n",
      "text node:\n",
      "  \n",
      "Element node: CD\n",
      "text node:\n",
      "    \n",
      "Element node: TITLE\n",
      "text node:Private Dancer\n",
      "text node:\n",
      "    \n",
      "Element node: ARTIST\n",
      "text node:Tina Turner\n",
      "text node:\n",
      "    \n",
      "Element node: COUNTRY\n",
      "text node:UK\n",
      "text node:\n",
      "    \n",
      "Element node: COMPANY\n",
      "text node:Capitol\n",
      "text node:\n",
      "    \n",
      "Element node: PRICE\n",
      "text node:8.90\n",
      "text node:\n",
      "    \n",
      "Element node: YEAR\n",
      "text node:1983\n",
      "text node:\n",
      "  \n",
      "text node:\n",
      "  \n",
      "Element node: CD\n",
      "text node:\n",
      "    \n",
      "Element node: TITLE\n",
      "text node:Midt om natten\n",
      "text node:\n",
      "    \n",
      "Element node: ARTIST\n",
      "text node:Kim Larsen\n",
      "text node:\n",
      "    \n",
      "Element node: COUNTRY\n",
      "text node:EU\n",
      "text node:\n",
      "    \n",
      "Element node: COMPANY\n",
      "text node:Medley\n",
      "text node:\n",
      "    \n",
      "Element node: PRICE\n",
      "text node:7.80\n",
      "text node:\n",
      "    \n",
      "Element node: YEAR\n",
      "text node:1983\n",
      "text node:\n",
      "  \n",
      "text node:\n",
      "  \n",
      "Element node: CD\n",
      "text node:\n",
      "    \n",
      "Element node: TITLE\n",
      "text node:Pavarotti Gala Concert\n",
      "text node:\n",
      "    \n",
      "Element node: ARTIST\n",
      "text node:Luciano Pavarotti\n",
      "text node:\n",
      "    \n",
      "Element node: COUNTRY\n",
      "text node:UK\n",
      "text node:\n",
      "    \n",
      "Element node: COMPANY\n",
      "text node:DECCA\n",
      "text node:\n",
      "    \n",
      "Element node: PRICE\n",
      "text node:9.90\n",
      "text node:\n",
      "    \n",
      "Element node: YEAR\n",
      "text node:1991\n",
      "text node:\n",
      "  \n",
      "text node:\n",
      "  \n",
      "Element node: CD\n",
      "text node:\n",
      "    \n",
      "Element node: TITLE\n",
      "text node:The dock of the bay\n",
      "text node:\n",
      "    \n",
      "Element node: ARTIST\n",
      "text node:Otis Redding\n",
      "text node:\n",
      "    \n",
      "Element node: COUNTRY\n",
      "text node:USA\n",
      "text node:\n",
      "    \n",
      "Element node: COMPANY\n",
      "text node:Stax Records\n",
      "text node:\n",
      "    \n",
      "Element node: PRICE\n",
      "text node:7.90\n",
      "text node:\n",
      "    \n",
      "Element node: YEAR\n",
      "text node:1968\n",
      "text node:\n",
      "  \n",
      "text node:\n",
      "  \n",
      "Element node: CD\n",
      "text node:\n",
      "    \n",
      "Element node: TITLE\n",
      "text node:Picture book\n",
      "text node:\n",
      "    \n",
      "Element node: ARTIST\n",
      "text node:Simply Red\n",
      "text node:\n",
      "    \n",
      "Element node: COUNTRY\n",
      "text node:EU\n",
      "text node:\n",
      "    \n",
      "Element node: COMPANY\n",
      "text node:Elektra\n",
      "text node:\n",
      "    \n",
      "Element node: PRICE\n",
      "text node:7.20\n",
      "text node:\n",
      "    \n",
      "Element node: YEAR\n",
      "text node:1985\n",
      "text node:\n",
      "  \n",
      "text node:\n",
      "  \n",
      "Element node: CD\n",
      "text node:\n",
      "    \n",
      "Element node: TITLE\n",
      "text node:Red\n",
      "text node:\n",
      "    \n",
      "Element node: ARTIST\n",
      "text node:The Communards\n",
      "text node:\n",
      "    \n",
      "Element node: COUNTRY\n",
      "text node:UK\n",
      "text node:\n",
      "    \n",
      "Element node: COMPANY\n",
      "text node:London\n",
      "text node:\n",
      "    \n",
      "Element node: PRICE\n",
      "text node:7.80\n",
      "text node:\n",
      "    \n",
      "Element node: YEAR\n",
      "text node:1987\n",
      "text node:\n",
      "  \n",
      "text node:\n",
      "  \n",
      "Element node: CD\n",
      "text node:\n",
      "    \n",
      "Element node: TITLE\n",
      "text node:Unchain my heart\n",
      "text node:\n",
      "    \n",
      "Element node: ARTIST\n",
      "text node:Joe Cocker\n",
      "text node:\n",
      "    \n",
      "Element node: COUNTRY\n",
      "text node:USA\n",
      "text node:\n",
      "    \n",
      "Element node: COMPANY\n",
      "text node:EMI\n",
      "text node:\n",
      "    \n",
      "Element node: PRICE\n",
      "text node:8.20\n",
      "text node:\n",
      "    \n",
      "Element node: YEAR\n",
      "text node:1987\n",
      "text node:\n",
      "  \n",
      "text node:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_page = urllib.request.urlopen(url)\n",
    "doc = minidom.parse(raw_page)\n",
    "\n",
    "def findTextnodes(nodeList):\n",
    "    for subnode in nodeList:\n",
    "        if subnode.nodeType == subnode.ELEMENT_NODE:\n",
    "            print(\"Element node: \" + subnode.tagName)\n",
    "            findTextnodes(subnode.childNodes)\n",
    "        elif subnode.nodeType == subnode.TEXT_NODE:\n",
    "            print(\"text node:\" + subnode.data)\n",
    "            \n",
    "findTextnodes(doc.childNodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empire Burlesque\n",
      "Hide your heart\n",
      "Greatest Hits\n",
      "Still got the blues\n",
      "Eros\n",
      "One night only\n",
      "Sylvias Mother\n",
      "Maggie May\n",
      "Romanza\n",
      "When a man loves a woman\n",
      "Black angel\n",
      "1999 Grammy Nominees\n",
      "For the good times\n",
      "Big Willie style\n",
      "Tupelo Honey\n",
      "Soulsville\n",
      "The very best of\n",
      "Stop\n",
      "Bridge of Spies\n",
      "Private Dancer\n",
      "Midt om natten\n",
      "Pavarotti Gala Concert\n",
      "The dock of the bay\n",
      "Picture book\n",
      "Red\n",
      "Unchain my heart\n"
     ]
    }
   ],
   "source": [
    "root = ET.fromstring(xml_page)\n",
    "cdtags = root.xpath('//CD/TITLE')\n",
    "for cd in cdtags:\n",
    "    print(cd.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bob Dylan\tUSA\tEmpire Burlesque\n",
      "Bonnie Tyler\tUK\tHide your heart\n",
      "Dolly Parton\tUSA\tGreatest Hits\n",
      "Gary Moore\tUK\tStill got the blues\n",
      "Eros Ramazzotti\tEU\tEros\n",
      "Bee Gees\tUK\tOne night only\n",
      "Dr.Hook\tUK\tSylvias Mother\n",
      "Rod Stewart\tUK\tMaggie May\n",
      "Andrea Bocelli\tEU\tRomanza\n",
      "Percy Sledge\tUSA\tWhen a man loves a woman\n",
      "Savage Rose\tEU\tBlack angel\n",
      "Many\tUSA\t1999 Grammy Nominees\n",
      "Kenny Rogers\tUK\tFor the good times\n",
      "Will Smith\tUSA\tBig Willie style\n",
      "Van Morrison\tUK\tTupelo Honey\n",
      "Jorn Hoel\tNorway\tSoulsville\n",
      "Cat Stevens\tUK\tThe very best of\n",
      "Sam Brown\tUK\tStop\n",
      "T'Pau\tUK\tBridge of Spies\n",
      "Tina Turner\tUK\tPrivate Dancer\n",
      "Kim Larsen\tEU\tMidt om natten\n",
      "Luciano Pavarotti\tUK\tPavarotti Gala Concert\n",
      "Otis Redding\tUSA\tThe dock of the bay\n",
      "Simply Red\tEU\tPicture book\n",
      "The Communards\tUK\tRed\n",
      "Joe Cocker\tUSA\tUnchain my heart\n"
     ]
    }
   ],
   "source": [
    "for cd in root.findall('CD'):\n",
    "    title = cd.find('TITLE').text\n",
    "    artist = cd.find('ARTIST').text\n",
    "    country = cd.find('COUNTRY').text\n",
    "    print('{}\\t{}\\t{}'.format(artist, country, title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'TITLE': 'Empire Burlesque',\n",
       "  'ARTIST': 'Bob Dylan',\n",
       "  'COUNTRY': 'USA',\n",
       "  'PRICE': '10.90',\n",
       "  'YEAR': '1985'},\n",
       " {'TITLE': 'Hide your heart',\n",
       "  'ARTIST': 'Bonnie Tyler',\n",
       "  'COUNTRY': 'UK',\n",
       "  'PRICE': '9.90',\n",
       "  'YEAR': '1988'},\n",
       " {'TITLE': 'Greatest Hits',\n",
       "  'ARTIST': 'Dolly Parton',\n",
       "  'COUNTRY': 'USA',\n",
       "  'PRICE': '9.90',\n",
       "  'YEAR': '1982'}]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cds = []\n",
    "for cd in root.findall('./CD'):\n",
    "        data = {}\n",
    "        data[\"TITLE\"] = cd.find('./TITLE').text\n",
    "        data[\"ARTIST\"] = cd.find('./ARTIST').text\n",
    "        data[\"COUNTRY\"] = cd.find('./COUNTRY').text\n",
    "        data[\"PRICE\"] = cd.find('./PRICE').text\n",
    "        data[\"YEAR\"] = cd.find('./YEAR').text\n",
    "        cds.append(data)\n",
    "cds[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Feeds RSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.feedparser.org/  \n",
    "http://docs.python.org/library/re.html  \n",
    "http://www.pythonware.com/library/pil/handbook/index.htm  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = feedparser.parse('https://oglobo.globo.com/rss.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OGlobo\n",
      "https://oglobo.globo.com/\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(d['feed']['title'])\n",
    "print(d['feed']['link'])\n",
    "#print(d.feed.subtitle)\n",
    "print(len(d['entries']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ComitÃª internacional envia dados de testes da CoronoVac para a Anvisa\n",
      "https://oglobo.globo.com/sociedade/comite-internacional-envia-dados-de-testes-da-coronovac-para-anvisa-24739295\n"
     ]
    }
   ],
   "source": [
    "print(d['entries'][0]['title']) \n",
    "print(d.entries[0]['link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Date': 'Tue, 10 Nov 2020 22:08:29 GMT', 'Server': 'Apache', 'Referrer-Policy': 'no-referrer-when-downgrade', 'Feature-Policy': \"geolocation 'none'; midi 'none'; microphone 'none'; camera 'none'; speaker 'self'; fullscreen 'self';\", 'X-Frame-Options': 'SAMEORIGIN', 'Expires': '1605046118811', 'Content-Type': 'application/rss+xml;charset=UTF-8', 'Access-Control-Allow-Origin': '*', 'Vary': 'Accept-Encoding', 'Content-Encoding': 'gzip', 'Content-Length': '2848', 'cache-control': 'public, max-age=602', 'Age': '55', 'grace': 'none', 'X-Cache': 'HIT', 'X-Cache-Hits': '2', 'Accept-Ranges': 'bytes', 'Strict-Transport-Security': 'max-age=15768000', 'Content-Security-Policy': \"default-src 'self' 'unsafe-inline' https: data: blob:; script-src 'self' 'unsafe-eval' 'unsafe-inline' https: blob:; img-src 'self' data: https:;\", 'X-XSS-Protection': '1; mode=block', 'Connection': 'close'}\n"
     ]
    }
   ],
   "source": [
    "print(d.headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ComitÃª internacional envia dados de testes da CoronoVac para a Anvisa: https://oglobo.globo.com/sociedade/comite-internacional-envia-dados-de-testes-da-coronovac-para-anvisa-24739295\n",
      "\n",
      "Ministro do STF dÃ¡ 48h para Anvisa prestar informaÃ§Ãµes sobre vacinas contra Covid-19: https://oglobo.globo.com/sociedade/coronavirus/ministro-do-stf-da-48h-para-anvisa-prestar-informacoes-sobre-vacinas-contra-covid-19-1-24739309\n",
      "\n",
      "Leandra Leal, Paolla Oliveira e Emanuelle AraÃºjo pedem ajuda a bloco carnavalesco centenÃ¡rio: https://oglobo.globo.com/cultura/leandra-leal-paolla-oliveira-emanuelle-araujo-pedem-ajuda-bloco-carnavalesco-centenario-24739164\n",
      "\n",
      "JustiÃ§a Eleitoral suspende propaganda de Crivella por exposiÃ§Ã£o excessiva de Bolsonaro: https://oglobo.globo.com/brasil/eleicoes-2020/justica-eleitoral-suspende-propaganda-de-crivella-por-exposicao-excessiva-de-bolsonaro-1-24739182\n",
      "\n",
      "Martha Rocha e Eduardo Paes sobem o tom e trocam acusaÃ§Ãµes na JustiÃ§a Eleitoral Ã s vÃ©speras do primeiro turno: https://oglobo.globo.com/brasil/martha-rocha-eduardo-paes-sobem-tom-trocam-acusacoes-na-justica-eleitoral-as-vesperas-do-primeiro-turno-24739192\n",
      "\n",
      "Executado no Rio, Fernando IggnÃ¡cio era inimigo declarado de RogÃ©rio Andrade: https://oglobo.globo.com/rio/executado-no-rio-fernando-iggnacio-era-inimigo-declarado-de-rogerio-andrade-24739308\n",
      "\n",
      "Candidatos a vereador novatos apostam em delivery de material, QR code e lives em campanha com covid-19: https://oglobo.globo.com/brasil/eleicoes-2020/candidatos-vereador-novatos-apostam-em-delivery-de-material-qr-code-lives-em-campanha-com-covid-19-24733377\n",
      "\n",
      "O sonho de morar no centro, pertinho do trabalho: https://oglobo.globo.com/brasil/o-sonho-de-morar-no-centro-pertinho-do-trabalho-24737458\n",
      "\n",
      "Guia: Como fazer cafÃ© coado no pano, na cafeteira italiana, na prensa francesa e na aeropress: https://oglobo.globo.com/sociedade/saude/guia-como-fazer-cafe-coado-no-pano-na-cafeteira-italiana-na-prensa-francesa-na-aeropress-24739149\n",
      "\n",
      "Levy Fidelix quer PRTB mais parecido com MourÃ£o: https://epoca.globo.com/guilherme-amado/levy-fidelix-quer-prtb-mais-parecido-com-mourao-24738837\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for post in d.entries:\n",
    "    print(post.title + \": \" + post.link + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Big Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'http://eforexcel.com/wp/wp-content/uploads/2017/07/1500000%20Sales%20Records.zip'\n",
    "filename = \"bigcsv.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../SampleDBs/bigcsv.zip', <http.client.HTTPMessage at 0x7fb67037ab50>)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(link, os.path.join(datapath, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Pandas with chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1500000 Sales Records.csv']\n",
      "Retrieving a new chunk\n",
      "                         Region           Country Item Type Sales Channel  \\\n",
      "0            Sub-Saharan Africa      South Africa    Fruits       Offline   \n",
      "1  Middle East and North Africa           Morocco   Clothes        Online   \n",
      "2         Australia and Oceania  Papua New Guinea      Meat       Offline   \n",
      "\n",
      "  Order Priority Order Date   Order ID   Ship Date  Units Sold  Unit Price  \\\n",
      "0              M  7/27/2012  443368995   7/28/2012        1593        9.33   \n",
      "1              M  9/14/2013  667593514  10/19/2013        4611      109.28   \n",
      "2              M  5/15/2015  940995585    6/4/2015         360      421.89   \n",
      "\n",
      "   Unit Cost  Total Revenue  Total Cost  Total Profit  \n",
      "0       6.92       14862.69    11023.56       3839.13  \n",
      "1      35.84      503890.08   165258.24     338631.84  \n",
      "2     364.69      151880.40   131288.40      20592.00  \n",
      "\n",
      "Retrieving a new chunk\n",
      "                       Region      Country      Item Type Sales Channel  \\\n",
      "100000     Sub-Saharan Africa   Madagascar         Cereal       Offline   \n",
      "100001  Australia and Oceania  New Zealand  Personal Care       Offline   \n",
      "100002     Sub-Saharan Africa       Malawi         Cereal       Offline   \n",
      "\n",
      "       Order Priority Order Date   Order ID  Ship Date  Units Sold  \\\n",
      "100000              L   1/9/2016  238872230  1/24/2016        6456   \n",
      "100001              C  6/14/2014  976817452  7/21/2014         846   \n",
      "100002              C  4/27/2017  371752727  6/10/2017        8748   \n",
      "\n",
      "        Unit Price  Unit Cost  Total Revenue  Total Cost  Total Profit  \n",
      "100000      205.70     117.11     1327999.20   756062.16     571937.04  \n",
      "100001       81.73      56.67       69143.58    47942.82      21200.76  \n",
      "100002      205.70     117.11     1799463.60  1024478.28     774985.32  \n",
      "\n",
      "Retrieving a new chunk\n",
      "                                   Region         Country        Item Type  \\\n",
      "200000                             Europe  Czech Republic  Office Supplies   \n",
      "200001  Central America and the Caribbean        Honduras           Snacks   \n",
      "200002       Middle East and North Africa    Saudi Arabia           Cereal   \n",
      "\n",
      "       Sales Channel Order Priority Order Date   Order ID   Ship Date  \\\n",
      "200000       Offline              M  8/30/2011  457898414   8/31/2011   \n",
      "200001        Online              L  12/6/2014  820111215  12/17/2014   \n",
      "200002       Offline              M  3/28/2014  134626567    4/2/2014   \n",
      "\n",
      "        Units Sold  Unit Price  Unit Cost  Total Revenue  Total Cost  \\\n",
      "200000        1171      651.21     524.96      762566.91   614728.16   \n",
      "200001        7988      152.58      97.44     1218809.04   778350.72   \n",
      "200002        7848      205.70     117.11     1614333.60   919079.28   \n",
      "\n",
      "        Total Profit  \n",
      "200000     147838.75  \n",
      "200001     440458.32  \n",
      "200002     695254.32  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "chunksize = 10 ** 5\n",
    "num_chunks_to_read = 3\n",
    "\n",
    "with ZipFile(os.path.join(datapath, filename), 'r') as myzip:\n",
    "    print(myzip.namelist())\n",
    "    unzipped = myzip.namelist()[0]\n",
    "    with myzip.open(unzipped) as myfile:\n",
    "        chunks = pd.read_csv((myfile), chunksize=chunksize) #, iterator=True)\n",
    "        for i in range(num_chunks_to_read):\n",
    "            print('Retrieving a new chunk')\n",
    "            df = chunks.get_chunk()\n",
    "            print(df.head(3))\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unzipping the file and reading line by line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile(os.path.join(datapath, filename), 'r') as myzip:\n",
    "    myzip.extractall(datapath)\n",
    "    myzip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getstuff(filename):\n",
    "    with open(filename, \"r\") as csvfile:\n",
    "        datareader = csv.reader(csvfile)\n",
    "        count = 0\n",
    "        for row in datareader:\n",
    "            yield(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Region', 'Country', 'Item Type', 'Sales Channel', 'Order Priority', 'Order Date', 'Order ID', 'Ship Date', 'Units Sold', 'Unit Price', 'Unit Cost', 'Total Revenue', 'Total Cost', 'Total Profit']\n",
      "['Sub-Saharan Africa', 'South Africa', 'Fruits', 'Offline', 'M', '7/27/2012', '443368995', '7/28/2012', '1593', '9.33', '6.92', '14862.69', '11023.56', '3839.13']\n",
      "['Middle East and North Africa', 'Morocco', 'Clothes', 'Online', 'M', '9/14/2013', '667593514', '10/19/2013', '4611', '109.28', '35.84', '503890.08', '165258.24', '338631.84']\n",
      "['Australia and Oceania', 'Papua New Guinea', 'Meat', 'Offline', 'M', '5/15/2015', '940995585', '6/4/2015', '360', '421.89', '364.69', '151880.40', '131288.40', '20592.00']\n",
      "['Sub-Saharan Africa', 'Djibouti', 'Clothes', 'Offline', 'H', '5/17/2017', '880811536', '7/2/2017', '562', '109.28', '35.84', '61415.36', '20142.08', '41273.28']\n",
      "['Europe', 'Slovakia', 'Beverages', 'Offline', 'L', '10/26/2016', '174590194', '12/4/2016', '3973', '47.45', '31.79', '188518.85', '126301.67', '62217.18']\n",
      "['Asia', 'Sri Lanka', 'Fruits', 'Online', 'L', '11/7/2011', '830192887', '12/18/2011', '1379', '9.33', '6.92', '12866.07', '9542.68', '3323.39']\n",
      "['Sub-Saharan Africa', 'Seychelles ', 'Beverages', 'Online', 'M', '1/18/2013', '425793445', '2/16/2013', '597', '47.45', '31.79', '28327.65', '18978.63', '9349.02']\n",
      "['Sub-Saharan Africa', 'Tanzania', 'Beverages', 'Online', 'L', '11/30/2016', '659878194', '1/16/2017', '1476', '47.45', '31.79', '70036.20', '46922.04', '23114.16']\n",
      "['Sub-Saharan Africa', 'Ghana', 'Office Supplies', 'Online', 'L', '3/23/2017', '601245963', '4/15/2017', '896', '651.21', '524.96', '583484.16', '470364.16', '113120.00']\n",
      "['Sub-Saharan Africa', 'Tanzania', 'Cosmetics', 'Offline', 'L', '5/23/2016', '739008080', '5/24/2016', '7768', '437.20', '263.33', '3396169.60', '2045547.44', '1350622.16']\n",
      "['Asia', 'Taiwan', 'Fruits', 'Offline', 'M', '2/9/2014', '732588374', '2/23/2014', '8034', '9.33', '6.92', '74957.22', '55595.28', '19361.94']\n",
      "['Middle East and North Africa', 'Algeria', 'Cosmetics', 'Online', 'M', '2/18/2011', '761723172', '2/24/2011', '9669', '437.20', '263.33', '4227286.80', '2546137.77', '1681149.03']\n",
      "['Asia', 'Singapore', 'Snacks', 'Online', 'C', '1/28/2013', '176461303', '2/7/2013', '7676', '152.58', '97.44', '1171204.08', '747949.44', '423254.64']\n",
      "['Australia and Oceania', 'Papua New Guinea', 'Clothes', 'Offline', 'L', '6/20/2011', '647164094', '7/14/2011', '9092', '109.28', '35.84', '993573.76', '325857.28', '667716.48']\n",
      "['Asia', 'Vietnam', 'Personal Care', 'Online', 'M', '4/4/2010', '314505374', '5/6/2010', '7984', '81.73', '56.67', '652532.32', '452453.28', '200079.04']\n",
      "['Sub-Saharan Africa', 'Uganda', 'Personal Care', 'Online', 'M', '6/19/2014', '539471471', '7/21/2014', '451', '81.73', '56.67', '36860.23', '25558.17', '11302.06']\n",
      "['Sub-Saharan Africa', 'Zimbabwe', 'Office Supplies', 'Offline', 'C', '3/28/2011', '953361213', '4/8/2011', '9623', '651.21', '524.96', '6266593.83', '5051690.08', '1214903.75']\n",
      "['Sub-Saharan Africa', 'Ethiopia', 'Cosmetics', 'Online', 'M', '7/7/2011', '807785928', '7/25/2011', '662', '437.20', '263.33', '289426.40', '174324.46', '115101.94']\n",
      "['Europe', 'France', 'Cosmetics', 'Online', 'M', '12/7/2015', '324669444', '1/18/2016', '5758', '437.20', '263.33', '2517397.60', '1516254.14', '1001143.46']\n",
      "['Central America and the Caribbean', 'The Bahamas', 'Personal Care', 'Online', 'C', '1/19/2011', '246248090', '2/21/2011', '9137', '81.73', '56.67', '746767.01', '517793.79', '228973.22']\n",
      "['Central America and the Caribbean', 'Haiti', 'Office Supplies', 'Online', 'C', '12/31/2010', '485070693', '1/31/2011', '2052', '651.21', '524.96', '1336282.92', '1077217.92', '259065.00']\n",
      "['Central America and the Caribbean', 'Nicaragua', 'Household', 'Online', 'C', '10/28/2015', '573998582', '12/7/2015', '7791', '668.27', '502.54', '5206491.57', '3915289.14', '1291202.43']\n",
      "['Asia', 'Turkmenistan', 'Vegetables', 'Online', 'M', '4/13/2015', '116205585', '6/2/2015', '6670', '154.06', '90.93', '1027580.20', '606503.10', '421077.10']\n",
      "['Europe', 'United Kingdom', 'Cosmetics', 'Online', 'L', '5/1/2015', '135178029', '5/16/2015', '1038', '437.20', '263.33', '453813.60', '273336.54', '180477.06']\n",
      "['Central America and the Caribbean', 'Dominican Republic', 'Baby Food', 'Offline', 'H', '8/25/2011', '824714744', '9/24/2011', '274', '255.28', '159.42', '69946.72', '43681.08', '26265.64']\n",
      "['Asia', 'China', 'Office Supplies', 'Online', 'M', '2/10/2016', '198927056', '3/29/2016', '5791', '651.21', '524.96', '3771157.11', '3040043.36', '731113.75']\n",
      "['Sub-Saharan Africa', 'Uganda', 'Cosmetics', 'Online', 'M', '2/28/2015', '842238795', '3/15/2015', '6031', '437.20', '263.33', '2636753.20', '1588143.23', '1048609.97']\n",
      "['Middle East and North Africa', 'Kuwait', 'Household', 'Offline', 'C', '6/13/2011', '459386289', '7/21/2011', '1466', '668.27', '502.54', '979683.82', '736723.64', '242960.18']\n",
      "['Middle East and North Africa', 'United Arab Emirates', 'Office Supplies', 'Online', 'M', '6/23/2012', '425418365', '7/6/2012', '9603', '651.21', '524.96', '6253569.63', '5041190.88', '1212378.75']\n",
      "['Europe', 'Estonia', 'Household', 'Offline', 'H', '9/1/2011', '835696351', '10/21/2011', '9976', '668.27', '502.54', '6666661.52', '5013339.04', '1653322.48']\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for row in getstuff(os.path.join(datapath, unzipped)):\n",
    "    print(row)\n",
    "    count +=1\n",
    "    if count > 30:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#erasing files\n",
    "os.remove(os.path.join(datapath, unzipped))\n",
    "os.remove(os.path.join(datapath, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using [HDF5](https://portal.hdfgroup.org/display/HDF5/HDF5)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!sudo pip install -q -U h5py  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "arr = np.random.randn(1000)\n",
    "\n",
    "filename = 'random.hdf5'\n",
    "#with h5py.File(os.path.join(datapath, filename), 'a') as f:   #if we'd like to append data\n",
    "with h5py.File(os.path.join(datapath, filename), 'w') as f:\n",
    "    dset = f.create_dataset(\"default\", data=arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets in ths hdf system: default\n",
      "<class 'h5py._hl.dataset.Dataset'>\n",
      "-2.7402203386874757\n",
      "3.7513257981483683\n",
      "[-1.0678731   1.88469368 -0.08366935  0.21702538  0.47980511 -0.35550758\n",
      " -1.59860092 -0.32225117 -0.26001115  0.51186456  0.5194933  -0.08569738\n",
      "  0.37366525  0.1688446  -0.27633071]\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(os.path.join(datapath, filename), 'r') as f:\n",
    "    for key in f.keys():\n",
    "        print(\"datasets in ths hdf system:\", key)\n",
    "    \n",
    "    data = f['default']\n",
    "    print(type(data))\n",
    "    print(min(data))\n",
    "    print(max(data))\n",
    "    print(data[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = np.random.randn(10000)\n",
    "arr2 = np.random.randn(10000)\n",
    "\n",
    "with h5py.File(os.path.join(datapath, filename), 'w') as f:\n",
    "    f.create_dataset('array_1', data=arr1)\n",
    "    f.create_dataset('array_2', data=arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'h5py._hl.dataset.Dataset'>\n",
      "<class 'h5py._hl.dataset.Dataset'>\n",
      "[ 0.07077221  0.09293002  0.121675   ...  1.87467458 -0.91006111\n",
      "  1.86608903]\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(os.path.join(datapath, filename), 'r') as f:\n",
    "    d1 = f['array_1']\n",
    "    d2 = f['array_2']\n",
    "    print(type(d1))\n",
    "    print(type(d2))\n",
    "    #data = d2[d1>0]  #error\n",
    "    data = d2[d1[:]>0]\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#erasing files\n",
    "\n",
    "os.remove(os.path.join(datapath, filename))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
